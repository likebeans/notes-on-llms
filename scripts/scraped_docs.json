[
  {
    "url": "https://deepspeed.readthedocs.io/en/latest/zero3.html",
    "title": "DeepSpeed ZeRO-3",
    "content": "ZeRO\n\nThe Zero Redundancy Optimizer (ZeRO) removes the memory redundancies across\ndata-parallel processes by partitioning the three model states (optimizer\nstates, gradients, and parameters) across data-parallel processes instead of\nreplicating them. By doing this, it boosts memory efficiency compared to\nclassic data-parallelism while retaining its computational granularity and\ncommunication efficiency.\nZeRO Stage 1\n: The optimizer states (e.g., for\nAdam optimizer\n, 32-bit weights, and the first, and second moment estimates) are partitioned across the processes, so that each process updates only its partition.\nZeRO Stage 2\n: The reduced 16-bit gradients for updating the model weights are also partitioned such that each process retains only the gradients corresponding to its portion of the optimizer states.\nZeRO Stage 3\n: The 16-bit model parameters are partitioned across the processes. ZeRO-3 will automatically collect and partition them during the forward and backward passes.\nIn addition, ZeRO-3 includes the\ninfinity offload engine\nto form\nZeRO-Infinity ([paper](\nhttps://arxiv.org/abs/2104.07857\n)), which can offload\nall model states to both CPU and NVMe memory for huge memory savings.\nFor a deep dive of our algorithms, please see our\npapers\non\nZeRO\n,\nZeRO-Offload\n,\nand\nZeRO-Infinity\n.\nNote\nDeepSpeed first included offloading capabilities with\nZeRO-Offload\n, a\nsystem for offloading optimizer and gradient states to CPU memory within\nZeRO-2.\nZeRO-Infinity\nis the next generation of offloading\ncapabilities, accessible to ZeRO-3. ZeRO-Infinity has all of the savings\nof ZeRO-Offload, plus is able to offload more the model weights and has\nmore effective bandwidth utilization and overlapping of computation and\ncommunication.\nGetting Started\n\nIf you are new to DeepSpeed, check out our\nGetting Started\npage.\nOnce you are training with DeepSpeed, enabling ZeRO-3 offload is as simple as enabling it\nin your DeepSpeed configuration! Below are a few examples of ZeRO-3 configurations. Please see\nour\nconfig guide\nfor a complete list of options for configuration and performance tuning.\nNote\nZeRO-Infinity and ZeRO-Offload work best with our heavily optimized\ndeepspeed.ops.adam.DeepSpeedCPUAdam\noptimizer. We recommend using\nour\noptimizer config\nto instruct\ndeepspeed.initialize()\nto build the optimizer for you.\nZeRO Configurations\n\nAll the settings for DeepSpeed ZeRO are set with the\nDeepSpeedZeroConfig\n.\nThe dictionary provided under the\nzero_optimization\nentry of the main\nDeepSpeed configuration dict will be parsed and validated with this class.\nSub-configurations for parameter offload and optimizer offload settings are\nparsed by\nDeepSpeedZeroOffloadParamConfig\nand\nDeepSpeedZeroOffloadOptimizerConfig\n.\nclass\ndeepspeed.runtime.zero.config.\nDeepSpeedZeroConfig\n[source]\n\nSets parameters for ZeRO optimizations.\nCreate a new model by parsing and validating input data from keyword arguments.\nRaises [\nValidationError\n][pydantic_core.ValidationError] if the input data cannot be\nvalidated to form a valid model.\nself\nis explicitly positional-only to allow\nself\nas a field name.\nstage\n:\nZeroStageEnum\n=\n0\n\nChooses different stages of ZeRO Optimizer. Stage 0, 1, 2, and 3 refer\nto disabled, optimizer state partitioning, and optimizer+gradient state\npartitioning, and optimizer+gradient+parameter partitioning, respectively.\ncontiguous_gradients\n:\nbool\n=\nTrue\n\nCopies the gradients to a contiguous buffer as they are produced. Avoids\nmemory fragmentation during backward pass.\nreduce_scatter\n:\nbool\n=\nTrue\n\nUses reduce or reduce scatter instead of allreduce to average gradients\nreduce_bucket_size\n:\nint\n=\n500,000,000\n\nNumber of elements reduced/allreduced at a time. Limits the memory required\nfor the allgather for large model sizes\nConstraints\nge\n= 0\nuse_multi_rank_bucket_allreduce\n:\nbool\n=\nTrue\n\nCombine the reduce buckets of the different ranks and do an All-Reduce instead of multiple Reduce ops.\nThis feature is useful when the model is small and we want to scale it on too many GPUs which therefore\nreduces the message sizes of each packet.\nallgather_partitions\n:\nbool\n=\nTrue\n\nChooses between allgather collective or a series of broadcast collectives\nto gather updated parameters from all the GPUs at the end of each step\nallgather_bucket_size\n:\nint\n=\n500,000,000\n\nNumber of elements allgathered at a time. Limits the memory required for\nthe allgather for large model sizes\nConstraints\nge\n= 0\noverlap_comm\n:\nOptional\n[\nbool\n]\n=\nNone\n\nAttempts to overlap the reduction of the gradients with backward computation\nload_from_fp32_weights\n:\nbool\n=\nTrue\n\nBoolean indicating whether to initialize fp32 master weights from fp32\ncopies in checkpoint (no precision loss) or from model’s fp16 copies (with\nprecision loss). This can be used to initialize optimizer state even when\ncheckpoint is missing optimizer state.\nelastic_checkpoint\n:\nbool\n=\nFalse\n\nEnable loading checkpoint that was saved by job with different GPU count.\nNo longer supported.\noffload_param\n:\nOptional\n[\nDeepSpeedZeroOffloadParamConfig\n]\n=\nNone\n\nEnable offloading of model parameters to CPU or NVMe. This frees up GPU\nmemory for larger models or batch sizes. Valid only with stage 3. Expects a\ndictionary containing values for\nDeepSpeedZeroOffloadParamConfig\n.\noffload_optimizer\n:\nOptional\n[\nDeepSpeedZeroOffloadOptimizerConfig\n]\n=\nNone\n\nEnable offloading of optimizer state to CPU or NVMe, and optimizer\ncomputation to CPU. This frees up GPU memory for larger models or batch\nsizes. Valid for ZeRO stage 1, 2, 3. Expects a dictionary containing values\nfor\nDeepSpeedZeroOffloadOptimizerConfig\n.\nzenflow\n:\nOptional\n[\nZenFlowConfig\n]\n=\nNone\n\nEnable ZenFlow\nsub_group_size\n:\nint\n=\n1,000,000,000\n\nTile size for parameter processing to fit massive models (with trillions of\nparameters). Used by ZeRO3-Offload and ZeRO-Infinity\nConstraints\nge\n= 0\ncpu_offload_param\n:\nOptional\n[\nbool\n]\n=\nNone\n\nDeprecated, please use\noffload_param\ncpu_offload_use_pin_memory\n:\nOptional\n[\nbool\n]\n=\nNone\n\nDeprecated, please use\noffload_param\nor\noffload_optimizer\ncpu_offload\n:\nOptional\n[\nbool\n]\n=\nNone\n\nDeprecated, please use\noffload_optimizer\nprefetch_bucket_size\n:\nint\n=\n50,000,000\n(alias\n'stage3_prefetch_bucket_size')\n\nMaximum number of parameter elements to fetch ahead of use. Used by ZeRO3,\nZeRO3-Offload, ZeRO-Infinity, and ZeRO-Inference.\nConstraints\nge\n= 0\nparam_persistence_threshold\n:\nint\n=\n100,000\n(alias\n'stage3_param_persistence_threshold')\n\nDo not partition parameters smaller than this threshold. Smaller values use\nless memory, but can greatly increase communication (especially\nlatency-bound messages).\nConstraints\nge\n= 0\nmodel_persistence_threshold\n:\nint\n=\nsys.maxsize\n(alias\n'stage3_model_persistence_threshold')\n\nMaximum number of parameter elements that can be persisted in GPU and not\npartitioned. This imposes an upper bound on the number of unpartitioned\nparameters resulting from param_persistence_threshold setting. Used by\nZeRO3-Offload, ZeRO-Infinity and ZeRO-Inference.\nConstraints\nge\n= 0\nmax_live_parameters\n:\nint\n=\n1,000,000,000\n(alias\n'stage3_max_live_parameters')\n\nThe maximum number of parameters resident per GPU before releasing. Smaller\nvalues use less memory, but perform more communication.\nConstraints\nge\n= 0\nmax_reuse_distance\n:\nint\n=\n1,000,000,000\n(alias\n'stage3_max_reuse_distance')\n\nDo not release a parameter if it will be reused within this threshold of\nparameters. Smaller values use less memory, but perform more communication.\nConstraints\nge\n= 0\ngather_16bit_weights_on_model_save\n:\nbool\n=\nFalse\n(alias\n'stage3_gather_16bit_weights_on_model_save')\n\nConsolidate the weights before saving the model by\nsave_16bit_model()\n.\nSince the weights are partitioned across GPUs, they aren’t part of\nstate_dict\n, so this function automatically gathers the weights when\nthis option is enabled and then saves the fp16 model weights.\nmodule_granularity_threshold\n:\nint\n=\n0\n(alias\n'stage3_module_granularity_threshold')\n\nThe granularity of a module is determined by the ratio of “parameter_count / (1 + descendant count)”.\nZeRO3 classifies modules with a granularity below the threshold as fine-grained,\nwhich are treated as integral units during parameter fetching. This reduces host overhead\nand the separate allgather overhead introduced by hooks for fine-grained layers when fetching parameters.\nuse_all_reduce_for_fetch_params\n:\nbool\n=\nFalse\n(alias\n'stage3_use_all_reduce_for_fetch_params')\n\nUse all_reduce op when fetching module parameters at stage3. This improves performance by reducing\nthe overhead of concatenation and slicing on the host.\nstage3_gather_fp16_weights_on_model_save\n:\nbool\n=\nFalse\n\nDeprecated, please use\ngather_16bit_weights_on_model_save\nignore_unused_parameters\n:\nbool\n=\nTrue\n\nUnused parameters in modules may be unexpected in static networks, but\ncould be normal in dynamic networks. This controls whether or not training\nshould terminate with an error message when unused parameters are detected.\nThis is set to\nTrue\nby default, which means unused parameters are\nignored and training continues. Now is just used in stage 2.\nlegacy_stage1\n:\nbool\n=\nFalse\n\nFor backward-compatibility enable old ZeRO stage 1 implementation. Use at\nyour own risk, will be deprecated soon.\nround_robin_gradients\n:\nbool\n=\nFalse\n\nStage 1 and 2 optimization for CPU offloading that parallelizes gradient\ncopying to CPU memory among ranks by fine-grained gradient partitioning.\nPerformance benefit grows with gradient accumulation steps (more copying\nbetween optimizer steps) or GPU count (increased parallelism).\nzero_hpz_partition_size\n:\nint\n=\n1\n\nNumber of ranks in zero parameters partitioning secondary group\nConstraints\nge\n= 0\nzero_quantized_weights\n:\nbool\n=\nFalse\n\nBoolean indicating whether to quantize zero parameters (weights)\nfor efficient all_gather comm\nzero_quantized_nontrainable_weights\n:\nbool\n=\nFalse\n\nBoolean indicating whether to quantize non-trainable zero parameters (weights)\nfor efficient memory usage and communication. Different from zero_quantized_weights\nthat stores the weights in original precision and only perform quantization during communication,\nthis flag will store the weights in quantized precision. This is useful for LoRA training.\nzero_quantized_gradients\n:\nbool\n=\nFalse\n\nBoolean indicating whether to use quantized zero gradients\nfor efficient all_2_all_reduce comm\nzeropp_loco_param\n:\nOptional\n[\nDict\n[\nstr\n,\nAny\n]\n]\n=\nNone\n\nThis dictionary contains parameters for using LoCo-Zero++, with two key parameters:\n-\nerr_beta\n: A coefficient for the moving average of quantization errors before and after gradient computation.\nIt ranges between 0 and 1, with a default value of 0.8.\n-\nreset_T\n: The number of steps after which the moving-average error buffer is cleared. The default value is 1024.\nThese parameters can be adjusted based on performance needs. Example configuration in ds config:\n“zeropp_loco_param”: { “err_beta”: 0.8, “reset_T”: 1024 }.\nSee LoCo paper for more details: (\nhttps://arxiv.org/abs/2407.04480\n).\nmics_shard_size\n:\nint\n=\n-1\n\nmics_hierarchical_params_gather\n:\nbool\n=\nFalse\n\nmemory_efficient_linear\n:\nbool\n=\nTrue\n\nUse memory efficient linear implementation, for Stage 3.\npipeline_loading_checkpoint\n:\nbool\n=\nFalse\n\noverride_module_apply\n:\nbool\n=\nTrue\n\nOverride nn.Module apply function, for Stage 3.\nlog_trace_cache_warnings\n:\nbool\n=\nFalse\n\nWhether to log warnings from trace cache, such as invalidation events.\nenable_sanity_checks\n:\nbool\n=\nFalse\n\nEnable internal sanity checks, which could be useful for debugging\nleaf_module\n:\nDeepSpeedZeroLeafModuleConfig\n[Optional]\n\nConfiguration for modules that should be treated as ZeRO3 leaf modules.\nclass\ndeepspeed.runtime.zero.config.\nDeepSpeedZeroOffloadParamConfig\n[source]\n\nSet options for parameter offload. Valid only with stage 3.\nCreate a new model by parsing and validating input data from keyword arguments.\nRaises [\nValidationError\n][pydantic_core.ValidationError] if the input data cannot be\nvalidated to form a valid model.\nself\nis explicitly positional-only to allow\nself\nas a field name.\ndevice\n:\nOffloadDeviceEnum\n=\n'none'\n\nDevice memory to offload model parameters. Supported options are\ncpu\nand\nnvme\n.\nnvme_path\n:\nOptional\n[\nPath\n]\n=\nNone\n\nFilesystem path for NVMe device for parameter offloading.\nbuffer_count\n:\nint\n=\n5\n\nNumber of buffers in buffer pool for parameter offloading to NVMe.\nConstraints\nge\n= 0\nbuffer_size\n:\nint\n=\n100,000,000\n\nSize of buffers in buffer pool for parameter offloading to NVMe.\nConstraints\nge\n= 0\nmax_in_cpu\n:\nint\n=\n1,000,000,000\n\nNumber of parameter elements to maintain in CPU memory when offloading to\nNVMe is enabled.\nConstraints\nge\n= 0\npin_memory\n:\nbool\n=\nFalse\n\nOffload to page-locked CPU memory. This could boost throughput at the cost\nof extra memory overhead.\nclass\ndeepspeed.runtime.zero.config.\nDeepSpeedZeroOffloadOptimizerConfig\n[source]\n\nSet options for optimizer offload. Valid with stage 1, 2, and 3.\nCreate a new model by parsing and validating input data from keyword arguments.\nRaises [\nValidationError\n][pydantic_core.ValidationError] if the input data cannot be\nvalidated to form a valid model.\nself\nis explicitly positional-only to allow\nself\nas a field name.\ndevice\n:\nOffloadDeviceEnum\n=\n'none'\n\nDevice memory to offload optimizer state. Supported options are\ncpu\nand\nnvme\n. Optimizer computation is offload to CPU regardless of device option.\nnvme_path\n:\nOptional\n[\nPath\n]\n=\nNone\n\nFilesystem path for NVMe device for optimizer state offloading.\nbuffer_count\n:\nint\n=\n4\n\nNumber of buffers in buffer pool for optimizer state offloading to NVMe.\nThis should be at least the number of states maintained per parameter by\nthe optimizer. For example, Adam optimizer has 4 states (parameter,\ngradient, momentum, and variance).\nConstraints\nge\n= 0\npin_memory\n:\nbool\n=\nFalse\n\nOffload to page-locked CPU memory. This could boost throughput at the cost\nof extra memory overhead.\npipeline_read\n:\nbool\n=\nFalse\n\nFor tile-based optimizer step processing, overlap read of next tile with\ncomputation of current tile. Used in ZeRO-Infinity.\npipeline_write\n:\nbool\n=\nFalse\n\nFor tile-based optimizer step processing, overlap write of previous tile\nwith computation of current tile.\nfast_init\n:\nbool\n=\nFalse\n\nEnable fast optimizer initialization when offloading to NVMe.\nratio\n:\nfloat\n=\n1.0\n\nPercentage of offloaded optimizer states to CPU Adam. Only valid with ZeRO Stage 3.\nConstraints\nge\n= 0.0\nle\n= 1.0\nsuper_offload\n:\nbool\n=\nFalse\n\nEnable high performance CPU offloading for Superchips. Only valid with ZeRO Stage 3.\ncpuadam_cores_perc\n:\nfloat\n=\n0.8\n\nPercentage of CPU cores to use for CPU Adam. Only valid with ZeRO Stage 3 and super_offload=True.\nConstraints\nge\n= 0.0\nle\n= 1.0\nExample ZeRO-3 Configurations\n\nUse ZeRO to partition the optimizer states (stage 1), gradients (stage 2),\nand parameters (stage 3).\n{\n\"zero_optimization\"\n:\n{\n\"stage\"\n:\n3\n,\n},\n\"fp16\"\n:\n{\n\"enabled\"\n:\ntrue\n},\n\"optimizer\"\n:\n{\n\"type\"\n:\n\"AdamW\"\n,\n\"params\"\n:\n{\n\"lr\"\n:\n0.001\n,\n\"betas\"\n:\n[\n0.8\n,\n0.999",
    "images": []
  }
]