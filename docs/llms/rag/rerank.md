---
title: é‡æ’åºæŠ€æœ¯è¯¦è§£
description: RAGç³»ç»Ÿä¸­çš„æ£€ç´¢ç»“æœé‡æ’åºä¸ç²¾æ’æŠ€æœ¯
---

# é‡æ’åºæŠ€æœ¯è¯¦è§£

> æå‡æ£€ç´¢ç²¾åº¦çš„å…³é”®æŠ€æœ¯ï¼Œä»ç²—æ’åˆ°ç²¾æ’çš„æ ¸å¿ƒç¯èŠ‚

## ğŸ¯ æ ¸å¿ƒæ¦‚å¿µ

### ä»€ä¹ˆæ˜¯é‡æ’åºï¼ˆRerankï¼‰ï¼Ÿ

**é‡æ’åº**æ˜¯RAGæ£€ç´¢æµç¨‹ä¸­çš„ç²¾æ’ç¯èŠ‚ï¼Œå¯¹åˆæ­¥æ£€ç´¢å¾—åˆ°çš„å€™é€‰æ–‡æ¡£è¿›è¡ŒäºŒæ¬¡æ’åºï¼Œç­›é€‰å‡ºæœ€ç›¸å…³çš„å†…å®¹ã€‚

**å…¸å‹æµç¨‹**ï¼š
```
ç”¨æˆ·æŸ¥è¯¢ â†’ ç²—æ’æ£€ç´¢(Top-100) â†’ é‡æ’åº(Top-10) â†’ LLMç”Ÿæˆ
```

### ä¸ºä»€ä¹ˆéœ€è¦é‡æ’åºï¼Ÿ

::: tip æ ¸å¿ƒä»·å€¼
**ç²¾åº¦æå‡**ï¼šé€šè¿‡æ›´å¤æ‚çš„æ¨¡å‹æé«˜åŒ¹é…ç²¾åº¦  
**è®¡ç®—å¹³è¡¡**ï¼šåœ¨é€Ÿåº¦å’Œè´¨é‡é—´æ‰¾åˆ°æœ€ä½³å¹³è¡¡ç‚¹  
**å¤šæ¨¡æ€èåˆ**ï¼šç»“åˆå¤šç§ç›¸å…³æ€§ä¿¡å·è¿›è¡Œç»¼åˆåˆ¤æ–­
:::

**é‡æ’åºçš„ä¼˜åŠ¿**ï¼š
- ä½¿ç”¨æ›´ç²¾ç¡®ä½†è®¡ç®—é‡å¤§çš„æ¨¡å‹
- è€ƒè™‘æŸ¥è¯¢å’Œæ–‡æ¡£çš„äº¤äº’ç‰¹å¾
- æ•´åˆå¤šç§ç›¸å…³æ€§ä¿¡å·
- å‡å°‘ä¼ é€’ç»™LLMçš„å™ªéŸ³

---

## ğŸ“Š é‡æ’åºæ–¹æ³•åˆ†ç±»

### æŒ‰æ¨¡å‹æ¶æ„åˆ†ç±»

| ç±»å‹ | åŸç† | ä¼˜åŠ¿ | åŠ£åŠ¿ | é€‚ç”¨åœºæ™¯ |
|------|------|------|------|----------|
| **Cross-Encoder** | æŸ¥è¯¢-æ–‡æ¡£è”åˆç¼–ç  | ç²¾åº¦æœ€é«˜ | è®¡ç®—é‡å¤§ | é«˜è´¨é‡è¦æ±‚ |
| **Bi-Encoder** | æŸ¥è¯¢å’Œæ–‡æ¡£åˆ†åˆ«ç¼–ç  | é€Ÿåº¦å¿« | äº¤äº’ä¸è¶³ | å¤§è§„æ¨¡æ£€ç´¢ |
| **Late Interaction** | å»¶è¿Ÿäº¤äº’è®¡ç®— | å¹³è¡¡ç²¾åº¦é€Ÿåº¦ | å®ç°å¤æ‚ | å¹³è¡¡åœºæ™¯ |

### æŒ‰æŠ€æœ¯è·¯å¾„åˆ†ç±»

| æ–¹æ³• | æŠ€æœ¯è¦ç‚¹ | ç‰¹ç‚¹ |
|------|----------|------|
| **åŸºäºä¼ ç»ŸML** | ç‰¹å¾å·¥ç¨‹+åˆ†ç±»å™¨ | å¯è§£é‡Šæ€§å¼º |
| **åŸºäºæ·±åº¦å­¦ä¹ ** | ç¥ç»ç½‘ç»œç›¸å…³æ€§å»ºæ¨¡ | æ•ˆæœæ›´å¥½ |
| **åŸºäºLLM** | å¤§æ¨¡å‹åˆ¤æ–­ç›¸å…³æ€§ | ç†è§£èƒ½åŠ›å¼º |
| **å¤šä¿¡å·èåˆ** | ç»“åˆå¤šç§ç›¸å…³æ€§æŒ‡æ ‡ | ç»¼åˆæ€§èƒ½å¥½ |

---

## ğŸ§  Cross-Encoder é‡æ’åº

### æ ¸å¿ƒåŸç†

Cross-Encoderå°†æŸ¥è¯¢å’Œæ–‡æ¡£æ‹¼æ¥è¾“å…¥ï¼Œé€šè¿‡Transformerè¿›è¡Œè”åˆç¼–ç ï¼Œè¾“å‡ºç›¸å…³æ€§åˆ†æ•°ï¼š

```python
# Cross-Encoderæ¶æ„
input = "[CLS] query [SEP] document [SEP]"
score = CrossEncoder(input)  # è¾“å‡º0-1ç›¸å…³æ€§åˆ†æ•°
```

### å®æˆ˜å®ç°

```python
from sentence_transformers import CrossEncoder
import numpy as np

class CrossEncoderReranker:
    def __init__(self, model_name='BAAI/bge-reranker-large'):
        """åˆå§‹åŒ–Cross-Encoderé‡æ’åºå™¨"""
        self.model = CrossEncoder(model_name)
        
    def rerank(self, query: str, documents: list, top_k: int = 5):
        """é‡æ’åºå®ç°"""
        if not documents:
            return []
        
        # 1. æ„å»ºæŸ¥è¯¢-æ–‡æ¡£å¯¹
        pairs = [(query, doc['text']) for doc in documents]
        
        # 2. æ‰¹é‡è®¡ç®—ç›¸å…³æ€§åˆ†æ•°
        scores = self.model.predict(pairs)
        
        # 3. é‡æ–°æ’åº
        scored_docs = []
        for doc, score in zip(documents, scores):
            doc_copy = doc.copy()
            doc_copy['rerank_score'] = float(score)
            scored_docs.append(doc_copy)
        
        # 4. æŒ‰åˆ†æ•°é™åºæ’åˆ—
        ranked_docs = sorted(scored_docs, key=lambda x: x['rerank_score'], reverse=True)
        
        return ranked_docs[:top_k]

# ä½¿ç”¨ç¤ºä¾‹
reranker = CrossEncoderReranker()

# å‡è®¾ä»ç¬¬ä¸€è½®æ£€ç´¢è·å¾—çš„å€™é€‰æ–‡æ¡£
candidates = [
    {'text': 'RAGæŠ€æœ¯ç»“åˆäº†æ£€ç´¢å’Œç”Ÿæˆï¼Œæå‡äº†å¤§æ¨¡å‹çš„çŸ¥è¯†è·å–èƒ½åŠ›', 'id': 'doc1'},
    {'text': 'å‘é‡æ•°æ®åº“æ˜¯å­˜å‚¨é«˜ç»´å‘é‡çš„ä¸“ç”¨æ•°æ®åº“ç³»ç»Ÿ', 'id': 'doc2'},
    {'text': 'æ£€ç´¢å¢å¼ºç”Ÿæˆé€šè¿‡å¤–éƒ¨çŸ¥è¯†åº“å¢å¼ºè¯­è¨€æ¨¡å‹çš„ç”Ÿæˆè´¨é‡', 'id': 'doc3'},
]

query = "ä»€ä¹ˆæ˜¯RAGæŠ€æœ¯ï¼Ÿ"
reranked = reranker.rerank(query, candidates, top_k=3)

print("é‡æ’åºç»“æœ:")
for i, doc in enumerate(reranked):
    print(f"{i+1}. åˆ†æ•°: {doc['rerank_score']:.3f}")
    print(f"   å†…å®¹: {doc['text']}")
    print("---")
```

### Cross-Encoderè¾“å‡ºå¤„ç†ï¼šLogitsåˆ°æ¦‚ç‡

> æ¥æºï¼š[æ··åˆæœç´¢ä¸­çš„åˆ†æ•°å½’ä¸€åŒ–æ–¹æ³•æ·±åº¦è§£æ](https://dd-ff.blog.csdn.net/article/details/156072979)

::: warning å…³é”®æ³¨æ„
Cross-Encoderï¼ˆå¦‚bge-rerankerï¼‰è¾“å‡ºçš„æ˜¯**åŸå§‹Logits**ï¼ˆå¯¹æ•°å‡ ç‡ï¼‰ï¼Œå®šä¹‰åŸŸä¸º(-âˆ, +âˆ)ã€‚ç›´æ¥å°†Logitsä¸å…¶ä»–åˆ†æ•°ï¼ˆå¦‚ä½™å¼¦ç›¸ä¼¼åº¦ï¼‰æ··åˆæ˜¯**æ•°å­¦è°¬è¯¯**ã€‚
:::

```python
import numpy as np

class CrossEncoderRerankerWithCalibration:
    """å¸¦æ¦‚ç‡æ ¡å‡†çš„Cross-Encoderé‡æ’åºå™¨"""
    
    def __init__(self, model_name='BAAI/bge-reranker-v2-m3'):
        from sentence_transformers import CrossEncoder
        self.model = CrossEncoder(model_name)
    
    def _sigmoid(self, x):
        """å°†Logitsè½¬æ¢ä¸ºæ¦‚ç‡"""
        return 1 / (1 + np.exp(-np.array(x)))
    
    def rerank(self, query: str, documents: list, top_k: int = 5, 
               return_probabilities: bool = True):
        """
        é‡æ’åºå¹¶è¿”å›æ ¡å‡†åçš„æ¦‚ç‡åˆ†æ•°
        
        Cross-Encoderè®­ç»ƒç›®æ ‡æ˜¯BCEWithLogitsLoss:
        - Logit > 0 æ„å‘³ç€ P(ç›¸å…³) > 0.5
        - Logit = 8.5  -> P = 0.9998 (é«˜ç›¸å…³)
        - Logit = -2.3 -> P = 0.0911 (ä½ç›¸å…³)
        """
        if not documents:
            return []
        
        pairs = [(query, doc['text']) for doc in documents]
        
        # è·å–åŸå§‹Logits
        logits = self.model.predict(pairs)
        
        # è½¬æ¢ä¸ºæ¦‚ç‡ï¼ˆæ¨èï¼‰
        if return_probabilities:
            scores = self._sigmoid(logits)
        else:
            scores = logits
        
        scored_docs = []
        for doc, score, logit in zip(documents, scores, logits):
            doc_copy = doc.copy()
            doc_copy['rerank_score'] = float(score)
            doc_copy['raw_logit'] = float(logit)
            scored_docs.append(doc_copy)
        
        ranked_docs = sorted(scored_docs, key=lambda x: x['rerank_score'], reverse=True)
        return ranked_docs[:top_k]

# ä½¿ç”¨ç¤ºä¾‹
reranker = CrossEncoderRerankerWithCalibration()
results = reranker.rerank("ä»€ä¹ˆæ˜¯RAGï¼Ÿ", candidates)

for doc in results:
    print(f"æ¦‚ç‡: {doc['rerank_score']:.3f} (Logit: {doc['raw_logit']:.2f})")
    # æ¦‚ç‡: 0.998 (Logit: 6.21)  <- é«˜ç›¸å…³
    # æ¦‚ç‡: 0.124 (Logit: -1.95) <- ä½ç›¸å…³
```

**ä¸ºä»€ä¹ˆå¿…é¡»è½¬æ¢ä¸ºæ¦‚ç‡ï¼Ÿ**
- **åˆ†æ•°å¯æ¯”æ€§**ï¼šæ¦‚ç‡å€¼[0,1]å¯ä¸ä½™å¼¦ç›¸ä¼¼åº¦ç›´æ¥èåˆ
- **é˜ˆå€¼æˆªæ–­**ï¼šæ¦‚ç‡æ”¯æŒè®¾ç½®ç»å¯¹è´¨é‡é˜ˆå€¼ï¼ˆå¦‚P<0.3æ‹’ç»å›ç­”ï¼‰
- **å¹»è§‰æŠ‘åˆ¶**ï¼šå³ä½¿æ‰€æœ‰æ–‡æ¡£éƒ½ä¸ç›¸å…³ï¼Œä¹Ÿèƒ½è¯†åˆ«å‡ºä½æ¦‚ç‡

### å¼€æºé‡æ’åºæ¨¡å‹å¯¹æ¯”

| æ¨¡å‹ | è¯­è¨€ | å‚æ•°é‡ | MTEBæ’å | ç‰¹ç‚¹ |
|------|------|--------|----------|------|
| **bge-reranker-v2-m3** | å¤šè¯­è¨€ | 568M | Top 1 | æœ€æ–°ç‰ˆæœ¬ï¼Œæ¨è |
| **bge-reranker-large** | ä¸­è‹± | 560M | Top 3 | æ€§èƒ½ä¼˜ç§€ï¼Œä¸­æ–‡å‹å¥½ |
| **bge-reranker-base** | ä¸­è‹± | 278M | Top 10 | å¹³è¡¡æ€§èƒ½ä¸é€Ÿåº¦ |
| **jina-reranker-v2** | å¤šè¯­è¨€ | 278M | - | å¤šè¯­è¨€æ”¯æŒ |
| **ms-marco-cross-encoder** | è‹±æ–‡ | 340M | - | ç»å…¸è‹±æ–‡æ¨¡å‹ |

---

## ğŸ›¡ï¸ Rerankä¿®æ­£æ£€ç´¢å¼‚å¸¸

> æ¥æºï¼š[æ··åˆæ£€ç´¢ä¸­çŸ­æŸ¥è¯¢é«˜åˆ†å¼‚å¸¸çš„æ·±åº¦å‰–æä¸ç¥ç»é‡æ’åºçš„ä¿®æ­£æœºåˆ¶](https://dd-ff.blog.csdn.net/article/details/156067548)

### çŸ­æŸ¥è¯¢é«˜åˆ†å¼‚å¸¸é—®é¢˜

::: danger ç—…æ€ç°è±¡
è¾“å…¥"Hello"ã€"ç³»ç»Ÿ"ã€"æµ‹è¯•"ç­‰çŸ­æŸ¥è¯¢æ—¶ï¼Œæ··åˆæ£€ç´¢å¾€å¾€ä»¥**æé«˜ç½®ä¿¡åº¦**è¿”å›**å®Œå…¨ä¸ç›¸å…³**çš„æ–‡æ¡£ã€‚è¿™åœ¨RAGä¸­æ˜¯è‡´å‘½çš„â€”â€”å™ªå£°ä¸Šä¸‹æ–‡ç›´æ¥å¯¼è‡´LLMå¹»è§‰ã€‚
:::

**æ ¹æœ¬åŸå› åˆ†æ**ï¼š

| æ£€ç´¢é˜¶æ®µ | å¤±æ•ˆæœºåˆ¶ | åæœ |
|----------|----------|------|
| **BM25** | IDFæƒé‡å´©æºƒ + é•¿åº¦åç½® | çŸ­ç¢ç‰‡é«˜åˆ† |
| **å‘é‡æ£€ç´¢** | å„å‘å¼‚æ€§ + æ¢çº½ç‚¹æ•ˆåº” | é€šç”¨æ–‡æ¡£é«˜åˆ† |
| **RRFèåˆ** | ç›²ä¿¡æ’åï¼Œæ”¾å¤§é”™è¯¯ | å™ªå£°å±…æ¦œé¦– |

### Cross-Encoderå¦‚ä½•ä¿®æ­£

**Bi-Encoder vs Cross-Encoder å¯¹æ¯”**ï¼š

```
Bi-Encoderï¼ˆå‘é‡æ£€ç´¢ï¼‰ï¼š
  Query  â”€â”€â”€â”€â†’ [Encoder] â”€â”€â”€â”€â†’ q_vec â”€â”
                                       â”œâ”€â†’ cosine(q, d) â†’ å—å‡ ä½•é™·é˜±å½±å“
  Doc    â”€â”€â”€â”€â†’ [Encoder] â”€â”€â”€â”€â†’ d_vec â”€â”˜

Cross-Encoderï¼ˆé‡æ’åºï¼‰ï¼š
  [CLS] Query [SEP] Doc [SEP] â”€â”€â”€â”€â†’ [Transformer] â”€â”€â”€â”€â†’ ç›¸å…³æ€§åˆ†æ•°
                                    â†‘
                                    é€è¯äº¤äº’ï¼Œæ¶ˆé™¤å‡ ä½•å™ªå£°
```

**ä¿®æ­£æœºåˆ¶**ï¼š

1. **æ¶ˆé™¤å‡ ä½•å™ªå£°**ï¼šé€šè¿‡è‡ªæ³¨æ„åŠ›æœºåˆ¶é€è¯åˆ†æï¼Œè¯†åˆ«"Hello"ä¸"ç”¨æˆ·åè®®"æ— è¯­ä¹‰è•´å«å…³ç³»
2. **è§£å†³é•¿åº¦åç½®**ï¼šé˜…è¯»å®Œæ•´ä¸Šä¸‹æ–‡ï¼Œè¯†åˆ«æ–‡æ¡£ä¸­çš„"Hello"è‹¥åªæ˜¯å­¤ç«‹è¯æ±‡åˆ™æ— æ³•å›ç­”æŸ¥è¯¢
3. **åˆ†æ•°æ ¡å‡†**ï¼šè¾“å‡ºæ¦‚ç‡å€¼ï¼Œæ”¯æŒç»å¯¹é˜ˆå€¼æˆªæ–­

### é˜ˆå€¼æˆªæ–­ä¸å¹»è§‰æŠ‘åˆ¶

```python
import numpy as np

class ThresholdedReranker:
    """å¸¦é˜ˆå€¼æˆªæ–­çš„é‡æ’åºå™¨ï¼Œç”¨äºæŠ‘åˆ¶RAGå¹»è§‰"""
    
    def __init__(self, model_name='BAAI/bge-reranker-v2-m3', 
                 threshold=0.3, min_results=0):
        from sentence_transformers import CrossEncoder
        self.model = CrossEncoder(model_name)
        self.threshold = threshold
        self.min_results = min_results  # æœ€å°‘è¿”å›æ•°é‡ï¼ˆ0è¡¨ç¤ºå¯è¿”å›ç©ºï¼‰
    
    def _sigmoid(self, x):
        return 1 / (1 + np.exp(-np.array(x)))
    
    def rerank(self, query: str, documents: list, top_k: int = 5):
        """
        é‡æ’åºå¹¶åº”ç”¨é˜ˆå€¼æˆªæ–­
        
        å…³é”®ï¼šè‹¥æ‰€æœ‰æ–‡æ¡£ç›¸å…³æ€§éƒ½ä½äºé˜ˆå€¼ï¼Œè¿”å›ç©ºåˆ—è¡¨
        è¿™ä¼˜äºè¿”å›å™ªå£°â€”â€”è®©ä¸‹æ¸¸ç³»ç»ŸçŸ¥é“"æ— å¯é ç­”æ¡ˆ"
        """
        if not documents:
            return [], "no_candidates"
        
        pairs = [(query, doc['text']) for doc in documents]
        logits = self.model.predict(pairs)
        probs = self._sigmoid(logits)
        
        scored_docs = []
        for doc, prob in zip(documents, probs):
            doc_copy = doc.copy()
            doc_copy['rerank_score'] = float(prob)
            scored_docs.append(doc_copy)
        
        # æŒ‰åˆ†æ•°æ’åº
        scored_docs.sort(key=lambda x: x['rerank_score'], reverse=True)
        
        # é˜ˆå€¼è¿‡æ»¤
        filtered = [d for d in scored_docs if d['rerank_score'] >= self.threshold]
        
        # åˆ¤æ–­ç»“æœçŠ¶æ€
        if len(filtered) == 0:
            if self.min_results > 0:
                # å¼ºåˆ¶è¿”å›topç»“æœï¼Œä½†æ ‡è®°ä¸ºä½ç½®ä¿¡
                return scored_docs[:self.min_results], "low_confidence"
            else:
                # è¿”å›ç©ºï¼Œè§¦å‘"æ— æ³•å›ç­”"é€»è¾‘
                return [], "no_relevant_docs"
        
        return filtered[:top_k], "success"

# ä½¿ç”¨ç¤ºä¾‹
reranker = ThresholdedReranker(threshold=0.3)

# æ­£å¸¸æŸ¥è¯¢
results, status = reranker.rerank("RAGæŠ€æœ¯çš„æ ¸å¿ƒåŸç†æ˜¯ä»€ä¹ˆï¼Ÿ", candidates)
# status: "success", results: [ç›¸å…³æ–‡æ¡£...]

# çŸ­æŸ¥è¯¢/æ— å…³æŸ¥è¯¢
results, status = reranker.rerank("Hello", candidates)
# status: "no_relevant_docs", results: []
# ä¸‹æ¸¸ç³»ç»Ÿåº”è¿”å›"æŠ±æ­‰ï¼Œæœªæ‰¾åˆ°ç›¸å…³ä¿¡æ¯"è€Œéå¹»è§‰å›ç­”
```

::: tip å¹»è§‰æŠ‘åˆ¶çš„å…³é”®
- **Min-Maxå½’ä¸€åŒ–å¤±è´¥**ï¼šå³ä½¿å…¨æ˜¯çƒ‚æ–‡æ¡£ï¼Œä¹Ÿä¼šåˆ¶é€ å‡º1.0åˆ†ï¼ŒLLMå¼ºè¡Œå›ç­”
- **Sigmoidæ¦‚ç‡èƒœåˆ©**ï¼šæä¾›ç»å¯¹é˜ˆå€¼ï¼Œä½äº0.3æ—¶æœæ–­æ‹’ç»ï¼Œé¿å…æ±¡æŸ“LLMä¸Šä¸‹æ–‡
:::

### å®Œæ•´ä¸¤é˜¶æ®µæ£€ç´¢æµæ°´çº¿

```python
class TwoStageRAGRetriever:
    """ç”Ÿäº§çº§ä¸¤é˜¶æ®µæ£€ç´¢å™¨"""
    
    def __init__(self, hybrid_retriever, reranker, 
                 recall_k=100, rerank_k=10, threshold=0.3):
        self.hybrid_retriever = hybrid_retriever
        self.reranker = reranker
        self.recall_k = recall_k
        self.rerank_k = rerank_k
        self.threshold = threshold
    
    def retrieve(self, query: str):
        """
        é˜¶æ®µ1ï¼šå¬å›ï¼ˆå®¹å¿å™ªå£°ï¼Œè¿½æ±‚é«˜å¬å›ç‡ï¼‰
        é˜¶æ®µ2ï¼šç²¾æ’ï¼ˆæ¶ˆé™¤å™ªå£°ï¼Œä¿è¯é«˜ç²¾åº¦ï¼‰
        """
        # é˜¶æ®µ1ï¼šæ··åˆæ£€ç´¢å¿«é€Ÿå¬å›
        candidates = self.hybrid_retriever.retrieve(query, top_k=self.recall_k)
        
        if not candidates:
            return {
                'documents': [],
                'status': 'no_candidates',
                'message': 'æœªæ£€ç´¢åˆ°ä»»ä½•å€™é€‰æ–‡æ¡£'
            }
        
        # é˜¶æ®µ2ï¼šCross-Encoderç²¾æ’
        pairs = [(query, doc['text']) for doc in candidates]
        logits = self.reranker.predict(pairs)
        probs = 1 / (1 + np.exp(-np.array(logits)))
        
        for doc, prob in zip(candidates, probs):
            doc['rerank_score'] = float(prob)
        
        candidates.sort(key=lambda x: x['rerank_score'], reverse=True)
        
        # é˜ˆå€¼è¿‡æ»¤
        filtered = [d for d in candidates if d['rerank_score'] >= self.threshold]
        
        if not filtered:
            return {
                'documents': [],
                'status': 'low_relevance',
                'message': 'æœªæ‰¾åˆ°ä¸æŸ¥è¯¢ç›¸å…³çš„é«˜è´¨é‡æ–‡æ¡£',
                'max_score': candidates[0]['rerank_score'] if candidates else 0
            }
        
        return {
            'documents': filtered[:self.rerank_k],
            'status': 'success',
            'message': f'æ‰¾åˆ° {len(filtered)} ä¸ªç›¸å…³æ–‡æ¡£'
        }

# é›†æˆåˆ°RAGç³»ç»Ÿ
class RAGSystem:
    def __init__(self, retriever, llm):
        self.retriever = retriever
        self.llm = llm
    
    def answer(self, query: str):
        result = self.retriever.retrieve(query)
        
        if result['status'] != 'success':
            # å…³é”®ï¼šæ‹’ç»å›ç­”è€Œéå¹»è§‰
            return f"æŠ±æ­‰ï¼Œ{result['message']}ï¼Œæ— æ³•å›ç­”æ‚¨çš„é—®é¢˜ã€‚"
        
        context = "\n\n".join([d['text'] for d in result['documents']])
        return self.llm.generate(query, context)
```

---

## âš¡ é«˜æ•ˆé‡æ’åºç­–ç•¥

### 1. åˆ†å±‚é‡æ’åº

```python
class HierarchicalReranker:
    def __init__(self, fast_reranker, precise_reranker):
        self.fast_reranker = fast_reranker      # è½»é‡çº§æ¨¡å‹
        self.precise_reranker = precise_reranker # ç²¾ç¡®æ¨¡å‹
    
    def rerank(self, query: str, documents: list, 
               stage1_top_k: int = 20, final_top_k: int = 5):
        """åˆ†å±‚é‡æ’åºï¼šå…ˆå¿«é€Ÿç­›é€‰ï¼Œå†ç²¾ç¡®æ’åº"""
        
        # ç¬¬ä¸€å±‚ï¼šå¿«é€Ÿç­›é€‰
        if len(documents) > stage1_top_k:
            stage1_results = self.fast_reranker.rerank(
                query, documents, top_k=stage1_top_k
            )
        else:
            stage1_results = documents
        
        # ç¬¬äºŒå±‚ï¼šç²¾ç¡®é‡æ’
        final_results = self.precise_reranker.rerank(
            query, stage1_results, top_k=final_top_k
        )
        
        return final_results

# ä½¿ç”¨ç¤ºä¾‹
from sentence_transformers import SentenceTransformer

# é…ç½®ä¸¤å±‚é‡æ’åºå™¨
fast_model = SentenceTransformer('BAAI/bge-base-zh-v1.5')  # å¿«é€Ÿæ¨¡å‹
precise_reranker = CrossEncoderReranker('BAAI/bge-reranker-large')  # ç²¾ç¡®æ¨¡å‹

class FastReranker:
    def __init__(self, model):
        self.model = model
    
    def rerank(self, query, documents, top_k):
        query_emb = self.model.encode(query)
        doc_embs = self.model.encode([doc['text'] for doc in documents])
        
        from sklearn.metrics.pairwise import cosine_similarity
        scores = cosine_similarity([query_emb], doc_embs)[0]
        
        scored_docs = []
        for doc, score in zip(documents, scores):
            doc_copy = doc.copy()
            doc_copy['fast_score'] = float(score)
            scored_docs.append(doc_copy)
        
        return sorted(scored_docs, key=lambda x: x['fast_score'], reverse=True)[:top_k]

fast_reranker = FastReranker(fast_model)
hierarchical = HierarchicalReranker(fast_reranker, precise_reranker)

# å¤„ç†å¤§é‡å€™é€‰æ–‡æ¡£
large_candidates = [{'text': f'æ–‡æ¡£{i}å†…å®¹...', 'id': f'doc{i}'} for i in range(100)]
results = hierarchical.rerank("æŸ¥è¯¢å†…å®¹", large_candidates, stage1_top_k=20, final_top_k=5)
```

### 2. LLM-as-Judge é‡æ’åº

```python
from openai import OpenAI

class LLMReranker:
    def __init__(self, model="gpt-3.5-turbo"):
        self.client = OpenAI()
        self.model = model
    
    def rerank(self, query: str, documents: list, top_k: int = 5):
        """ä½¿ç”¨LLMè¿›è¡Œé‡æ’åº"""
        if len(documents) <= top_k:
            return documents
        
        # æ„å»ºé‡æ’åºæç¤ºè¯
        doc_list = ""
        for i, doc in enumerate(documents):
            doc_list += f"[{i+1}] {doc['text'][:200]}...\n\n"
        
        prompt = f"""
è¯·æ ¹æ®æŸ¥è¯¢å†…å®¹å¯¹ä»¥ä¸‹æ–‡æ¡£æŒ‰ç›¸å…³æ€§è¿›è¡Œæ’åºï¼Œåªéœ€è¦è¿”å›æœ€ç›¸å…³çš„{top_k}ä¸ªæ–‡æ¡£çš„ç¼–å·ã€‚

æŸ¥è¯¢ï¼š{query}

æ–‡æ¡£åˆ—è¡¨ï¼š
{doc_list}

è¯·è¿”å›æœ€ç›¸å…³çš„{top_k}ä¸ªæ–‡æ¡£ç¼–å·ï¼ŒæŒ‰ç›¸å…³æ€§ä»é«˜åˆ°ä½æ’åˆ—ï¼Œæ ¼å¼å¦‚ï¼š[1, 3, 5, 2, 4]
"""

        try:
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[{"role": "user", "content": prompt}],
                temperature=0.1
            )
            
            # è§£æLLMè¿”å›çš„æ’åºç»“æœ
            result_text = response.choices[0].message.content.strip()
            
            # æå–æ•°å­—åºåˆ—
            import re
            numbers = re.findall(r'\d+', result_text)
            selected_indices = [int(n)-1 for n in numbers[:top_k] if 0 <= int(n)-1 < len(documents)]
            
            # æŒ‰LLMæ’åºè¿”å›æ–‡æ¡£
            reranked_docs = []
            for idx in selected_indices:
                doc_copy = documents[idx].copy()
                doc_copy['llm_rank'] = len(reranked_docs) + 1
                reranked_docs.append(doc_copy)
            
            return reranked_docs
            
        except Exception as e:
            print(f"LLMé‡æ’åºå¤±è´¥: {e}")
            # é™çº§åˆ°åŸå§‹æ’åº
            return documents[:top_k]

# ä½¿ç”¨ç¤ºä¾‹
llm_reranker = LLMReranker()
results = llm_reranker.rerank(query, candidates, top_k=3)

print("LLMé‡æ’åºç»“æœ:")
for doc in results:
    print(f"æ’å: {doc['llm_rank']}")
    print(f"å†…å®¹: {doc['text'][:100]}...")
    print("---")
```

### 3. å¤šä¿¡å·èåˆé‡æ’åº

```python
class MultiSignalReranker:
    def __init__(self, rerankers, weights=None):
        """
        å¤šä¿¡å·èåˆé‡æ’åºå™¨
        rerankers: ä¸åŒçš„é‡æ’åºå™¨åˆ—è¡¨
        weights: å„é‡æ’åºå™¨çš„æƒé‡
        """
        self.rerankers = rerankers
        self.weights = weights or [1.0] * len(rerankers)
    
    def rerank(self, query: str, documents: list, top_k: int = 5):
        """èåˆå¤šä¸ªé‡æ’åºä¿¡å·"""
        all_scores = {}
        
        # 1. è·å–å„ä¸ªé‡æ’åºå™¨çš„åˆ†æ•°
        for i, reranker in enumerate(self.rerankers):
            try:
                ranked_docs = reranker.rerank(query, documents, top_k=len(documents))
                
                for j, doc in enumerate(ranked_docs):
                    doc_id = doc.get('id', j)
                    if doc_id not in all_scores:
                        all_scores[doc_id] = {'doc': doc, 'scores': []}
                    
                    # å½’ä¸€åŒ–åˆ†æ•°ï¼ˆæ’åè½¬åˆ†æ•°ï¼‰
                    normalized_score = (len(ranked_docs) - j) / len(ranked_docs)
                    all_scores[doc_id]['scores'].append(normalized_score * self.weights[i])
                    
            except Exception as e:
                print(f"é‡æ’åºå™¨{i}å¤±è´¥: {e}")
                continue
        
        # 2. è®¡ç®—èåˆåˆ†æ•°
        final_docs = []
        for doc_id, data in all_scores.items():
            doc = data['doc'].copy()
            # åŠ æƒå¹³å‡
            final_score = sum(data['scores']) / len(data['scores'])
            doc['fusion_score'] = final_score
            final_docs.append(doc)
        
        # 3. æŒ‰èåˆåˆ†æ•°æ’åº
        final_docs.sort(key=lambda x: x['fusion_score'], reverse=True)
        return final_docs[:top_k]

# ä½¿ç”¨ç¤ºä¾‹ï¼šèåˆä¸‰ç§é‡æ’åºæ–¹æ³•
rerankers = [
    CrossEncoderReranker('BAAI/bge-reranker-base'),
    fast_reranker,  # åŸºäºå‘é‡ç›¸ä¼¼åº¦
    llm_reranker    # åŸºäºLLMåˆ¤æ–­
]

weights = [0.5, 0.3, 0.2]  # Cross-Encoderæƒé‡æœ€é«˜
fusion_reranker = MultiSignalReranker(rerankers, weights)

results = fusion_reranker.rerank(query, candidates, top_k=5)
print("èåˆé‡æ’åºç»“æœ:")
for doc in results:
    print(f"èåˆåˆ†æ•°: {doc['fusion_score']:.3f}")
    print(f"å†…å®¹: {doc['text'][:100]}...")
    print("---")
```

---

## ğŸ“Š é‡æ’åºæ€§èƒ½ä¼˜åŒ–

### 1. æ‰¹é‡å¤„ç†ä¼˜åŒ–

```python
class BatchReranker:
    def __init__(self, base_reranker, batch_size=32):
        self.base_reranker = base_reranker
        self.batch_size = batch_size
    
    def batch_rerank(self, query_doc_pairs: list):
        """æ‰¹é‡é‡æ’åºå¤„ç†"""
        results = []
        
        for i in range(0, len(query_doc_pairs), self.batch_size):
            batch = query_doc_pairs[i:i + self.batch_size]
            
            # æ‰¹é‡å¤„ç†
            batch_queries = [pair['query'] for pair in batch]
            batch_docs = [pair['documents'] for pair in batch]
            
            # è¿™é‡Œéœ€è¦æ ¹æ®å…·ä½“rerankerå®ç°æ‰¹é‡æ¥å£
            batch_results = []
            for query, docs in zip(batch_queries, batch_docs):
                result = self.base_reranker.rerank(query, docs)
                batch_results.append(result)
            
            results.extend(batch_results)
        
        return results
```

### 2. ç¼“å­˜æœºåˆ¶

```python
import hashlib
import json
from functools import lru_cache

class CachedReranker:
    def __init__(self, base_reranker, cache_size=10000):
        self.base_reranker = base_reranker
        self.cache = {}
        self.cache_size = cache_size
    
    def _get_cache_key(self, query, documents):
        """ç”Ÿæˆç¼“å­˜é”®"""
        doc_texts = [doc['text'] for doc in documents]
        content = f"{query}:{':'.join(doc_texts)}"
        return hashlib.md5(content.encode()).hexdigest()
    
    def rerank(self, query: str, documents: list, top_k: int = 5):
        """å¸¦ç¼“å­˜çš„é‡æ’åº"""
        cache_key = self._get_cache_key(query, documents)
        
        # å°è¯•ä»ç¼“å­˜è·å–
        if cache_key in self.cache:
            return self.cache[cache_key][:top_k]
        
        # è®¡ç®—é‡æ’åºç»“æœ
        results = self.base_reranker.rerank(query, documents, top_k)
        
        # ç¼“å­˜ç»“æœ
        if len(self.cache) >= self.cache_size:
            # ç®€å•çš„FIFOæ¸…ç†ç­–ç•¥
            oldest_key = next(iter(self.cache))
            del self.cache[oldest_key]
        
        self.cache[cache_key] = results
        return results

# ä½¿ç”¨ç¤ºä¾‹
cached_reranker = CachedReranker(
    CrossEncoderReranker('BAAI/bge-reranker-base'),
    cache_size=5000
)
```

---

## ğŸ”§ é‡æ’åºè¯„ä¼°ä¸è°ƒä¼˜

### 1. é‡æ’åºæ•ˆæœè¯„ä¼°

```python
import numpy as np
from sklearn.metrics import ndcg_score

class RerankEvaluator:
    def __init__(self, test_data):
        """
        test_data: [
            {
                'query': 'query text',
                'documents': [{'text': '...', 'relevance': 0/1}],
            }
        ]
        """
        self.test_data = test_data
    
    def evaluate_reranker(self, reranker, metrics=['ndcg', 'map', 'mrr']):
        """è¯„ä¼°é‡æ’åºæ•ˆæœ"""
        results = {metric: [] for metric in metrics}
        
        for item in self.test_data:
            query = item['query']
            documents = item['documents']
            
            # è·å–é‡æ’åºç»“æœ
            reranked = reranker.rerank(query, documents, top_k=len(documents))
            
            # æå–ç›¸å…³æ€§æ ‡ç­¾å’Œé¢„æµ‹åˆ†æ•°
            y_true = [doc.get('relevance', 0) for doc in documents]
            y_pred = []
            
            for doc in reranked:
                # æ‰¾åˆ°åŸæ–‡æ¡£çš„ç›¸å…³æ€§
                original_idx = documents.index(doc)
                y_pred.append(doc.get('rerank_score', 1.0))
            
            # è®¡ç®—å„é¡¹æŒ‡æ ‡
            if 'ndcg' in metrics:
                ndcg = ndcg_score([y_true], [y_pred])
                results['ndcg'].append(ndcg)
            
            if 'map' in metrics:
                map_score = self._calculate_map(y_true, y_pred)
                results['map'].append(map_score)
            
            if 'mrr' in metrics:
                mrr_score = self._calculate_mrr(y_true, y_pred)
                results['mrr'].append(mrr_score)
        
        # è®¡ç®—å¹³å‡å€¼
        avg_results = {k: np.mean(v) for k, v in results.items()}
        return avg_results
    
    def _calculate_map(self, y_true, y_pred):
        """è®¡ç®—å¹³å‡ç²¾åº¦å‡å€¼"""
        # å®ç°MAPè®¡ç®—é€»è¾‘
        pass
    
    def _calculate_mrr(self, y_true, y_pred):
        """è®¡ç®—å¹³å‡å€’æ•°æ’å"""
        # å®ç°MRRè®¡ç®—é€»è¾‘
        pass

# ä½¿ç”¨ç¤ºä¾‹
evaluator = RerankEvaluator(test_data)
metrics = evaluator.evaluate_reranker(reranker)
print("é‡æ’åºè¯„ä¼°ç»“æœ:")
for metric, value in metrics.items():
    print(f"{metric.upper()}: {value:.3f}")
```

### 2. å‚æ•°è°ƒä¼˜æŒ‡å—

| å‚æ•° | å»ºè®®å€¼ | å½±å“ | è°ƒä¼˜ç­–ç•¥ |
|------|--------|------|----------|
| **top_k** | 5-10 | ç²¾æ’å€™é€‰æ•°é‡ | æ ¹æ®ä¸‹æ¸¸LLMå¤„ç†èƒ½åŠ›è°ƒæ•´ |
| **é˜ˆå€¼** | 0.5-0.8 | ç›¸å…³æ€§è¿‡æ»¤ | é€šè¿‡éªŒè¯é›†ç¡®å®š |
| **èåˆæƒé‡** | [0.6, 0.3, 0.1] | å¤šä¿¡å·é‡è¦æ€§ | A/Bæµ‹è¯•ä¼˜åŒ– |
| **æ‰¹é‡å¤§å°** | 16-64 | å¤„ç†æ•ˆç‡ | æ ¹æ®GPUæ˜¾å­˜è°ƒæ•´ |

---

## âš ï¸ å¸¸è§é—®é¢˜ä¸è§£å†³

### é—®é¢˜1ï¼šé‡æ’åºé€Ÿåº¦æ…¢

**ç°è±¡**ï¼šé‡æ’åºæˆä¸ºç³»ç»Ÿç“¶é¢ˆ  
**è§£å†³æ–¹æ¡ˆ**ï¼š

```python
# 1. å¼‚æ­¥é‡æ’åº
import asyncio
import concurrent.futures

class AsyncReranker:
    def __init__(self, base_reranker, max_workers=4):
        self.base_reranker = base_reranker
        self.max_workers = max_workers
    
    async def async_rerank(self, query_batches):
        """å¼‚æ­¥æ‰¹é‡é‡æ’åº"""
        loop = asyncio.get_event_loop()
        
        with concurrent.futures.ThreadPoolExecutor(max_workers=self.max_workers) as executor:
            tasks = []
            for query, docs in query_batches:
                task = loop.run_in_executor(
                    executor, 
                    self.base_reranker.rerank, 
                    query, docs
                )
                tasks.append(task)
            
            results = await asyncio.gather(*tasks)
            return results

# 2. é¢„è®¡ç®—ä¼˜åŒ–
class PrecomputedReranker:
    def __init__(self):
        self.precomputed_scores = {}  # é¢„è®¡ç®—çš„æŸ¥è¯¢-æ–‡æ¡£å¯¹åˆ†æ•°
    
    def precompute_common_pairs(self, common_queries, document_pool):
        """é¢„è®¡ç®—å¸¸è§æŸ¥è¯¢çš„é‡æ’åºåˆ†æ•°"""
        for query in common_queries:
            for doc in document_pool:
                key = (query, doc['id'])
                score = self._compute_score(query, doc['text'])
                self.precomputed_scores[key] = score
    
    def rerank(self, query, documents, top_k=5):
        """ä½¿ç”¨é¢„è®¡ç®—åˆ†æ•°çš„å¿«é€Ÿé‡æ’åº"""
        scored_docs = []
        for doc in documents:
            key = (query, doc['id'])
            if key in self.precomputed_scores:
                score = self.precomputed_scores[key]
            else:
                score = self._compute_score(query, doc['text'])
            
            doc_copy = doc.copy()
            doc_copy['rerank_score'] = score
            scored_docs.append(doc_copy)
        
        return sorted(scored_docs, key=lambda x: x['rerank_score'], reverse=True)[:top_k]
```

### é—®é¢˜2ï¼šé‡æ’åºæ•ˆæœä¸ä½³

**ç°è±¡**ï¼šé‡æ’åºåç›¸å…³æ€§ä»ç„¶ä¸é«˜  
**è§£å†³ç­–ç•¥**ï¼š

```python
# 1. æ¨¡å‹å¾®è°ƒ
class FineTunedReranker:
    def __init__(self, base_model_path, training_data):
        self.model_path = base_model_path
        self.training_data = training_data
    
    def fine_tune(self, epochs=3, learning_rate=2e-5):
        """åœ¨ç‰¹å®šæ•°æ®ä¸Šå¾®è°ƒé‡æ’åºæ¨¡å‹"""
        from sentence_transformers import CrossEncoder, InputExample
        
        # å‡†å¤‡è®­ç»ƒæ•°æ®
        train_examples = []
        for item in self.training_data:
            query = item['query']
            for doc in item['documents']:
                example = InputExample(
                    texts=[query, doc['text']], 
                    label=doc['relevance']
                )
                train_examples.append(example)
        
        # åŠ è½½å¹¶å¾®è°ƒæ¨¡å‹
        model = CrossEncoder(self.model_path)
        model.fit(
            train_examples,
            epochs=epochs,
            warmup_steps=100,
            output_path=f"{self.model_path}_finetuned"
        )
        
        return f"{self.model_path}_finetuned"

# 2. é¢†åŸŸé€‚é…
class DomainAdaptedReranker:
    def __init__(self, general_reranker, domain_keywords):
        self.general_reranker = general_reranker
        self.domain_keywords = domain_keywords
    
    def rerank(self, query, documents, top_k=5):
        """é¢†åŸŸé€‚é…çš„é‡æ’åº"""
        # å…ˆè¿›è¡Œé€šç”¨é‡æ’åº
        general_results = self.general_reranker.rerank(query, documents, top_k * 2)
        
        # é¢†åŸŸå…³é”®è¯åŠ æƒ
        for doc in general_results:
            domain_boost = 0
            for keyword in self.domain_keywords:
                if keyword.lower() in doc['text'].lower():
                    domain_boost += 0.1
            
            doc['rerank_score'] += domain_boost
        
        # é‡æ–°æ’åº
        final_results = sorted(general_results, key=lambda x: x['rerank_score'], reverse=True)
        return final_results[:top_k]
```

---

## ğŸ”— ç›¸å…³é˜…è¯»

- [RAGèŒƒå¼æ¼”è¿›](/llms/rag/paradigms) - äº†è§£RAGæŠ€æœ¯å‘å±•è„‰ç»œ
- [æ£€ç´¢ç­–ç•¥ä¼˜åŒ–](/llms/rag/retrieval) - é‡æ’åºçš„ä¸Šæ¸¸ç¯èŠ‚
- [RAGè¯„ä¼°æ–¹æ³•](/llms/rag/evaluation) - é‡æ’åºæ•ˆæœè¯„ä¼°
- [å‘é‡æ•°æ®åº“](/llms/rag/vector-db) - æ£€ç´¢çš„åº•å±‚å­˜å‚¨
- [ç”Ÿäº§å®è·µæŒ‡å—](/llms/rag/production) - é‡æ’åºçš„éƒ¨ç½²ä¼˜åŒ–

> **ç›¸å…³æ–‡ç« **ï¼š
> - [æ··åˆæœç´¢ä¸­çš„åˆ†æ•°å½’ä¸€åŒ–æ–¹æ³•æ·±åº¦è§£æ](https://dd-ff.blog.csdn.net/article/details/156072979)
> - [æ··åˆæ£€ç´¢ä¸­çŸ­æŸ¥è¯¢é«˜åˆ†å¼‚å¸¸çš„æ·±åº¦å‰–æä¸ç¥ç»é‡æ’åºçš„ä¿®æ­£æœºåˆ¶](https://dd-ff.blog.csdn.net/article/details/156067548)
> - [é«˜çº§RAGæŠ€æœ¯å…¨æ™¯ï¼šä»åŸç†åˆ°å®æˆ˜](https://dd-ff.blog.csdn.net/article/details/149396526)
> - [æ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRAGï¼‰ç³»ç»Ÿç»¼åˆè¯„ä¼°](https://dd-ff.blog.csdn.net/article/details/152823514)
> - [æ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRAGï¼‰ç»¼è¿°ï¼šæŠ€æœ¯èŒƒå¼ã€æ ¸å¿ƒç»„ä»¶ä¸æœªæ¥å±•æœ›](https://dd-ff.blog.csdn.net/article/details/149274498)

> **å¤–éƒ¨èµ„æº**ï¼š
> - [BGE-Rerankeræ¨¡å‹](https://huggingface.co/BAAI/bge-reranker-v2-m3) - æ™ºæºå¼€æºé‡æ’åºæ¨¡å‹
> - [Cohere Rerank API](https://docs.cohere.com/docs/rerank) - å•†ä¸šé‡æ’åºæœåŠ¡
> - [Cross-EncoderåŸç†](https://www.sbert.net/examples/applications/cross-encoder/README.html) - Sentence-Transformersæ–‡æ¡£
