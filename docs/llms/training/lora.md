---
title: LoRA é«˜æ•ˆå¾®è°ƒ
description: Low-Rank Adaptation - ç”¨1%å‚æ•°è¾¾åˆ°å…¨é‡å¾®è°ƒæ•ˆæœ
---

# LoRA é«˜æ•ˆå¾®è°ƒ

> è®©æ¶ˆè´¹çº§æ˜¾å¡ä¹Ÿèƒ½å¾®è°ƒå¤§æ¨¡å‹

## ğŸ¯ æ ¸å¿ƒæ¦‚å¿µ

> æ¥æºï¼š[Fine-Tuning using LoRA and QLoRA - GeeksforGeeks](https://www.geeksforgeeks.org/deep-learning/fine-tuning-using-lora-and-qlora/) | [PEFTæŠ€æœ¯æ·±åº¦è§£æ](https://dd-ff.blog.csdn.net/article/details/153965724)

![LoRA vs QLoRA](https://media.geeksforgeeks.org/wp-content/uploads/20250429165859333373/Fine-Tunning-LLMS-with-Qlora.webp)
*LoRA vs QLoRA å¯¹æ¯”*

### ä»€ä¹ˆæ˜¯LoRAï¼Ÿ

::: tip å®šä¹‰
**LoRAï¼ˆLow-Rank Adaptationï¼‰** æ˜¯ä¸€ç§å‚æ•°é«˜æ•ˆå¾®è°ƒï¼ˆPEFTï¼‰æŠ€æœ¯ï¼Œé€šè¿‡åœ¨é¢„è®­ç»ƒæƒé‡æ—è¾¹æ³¨å…¥å¯è®­ç»ƒçš„ä½ç§©çŸ©é˜µï¼Œä»…æ›´æ–° **0.5-5%** çš„å‚æ•°å³å¯è¾¾åˆ°æ¥è¿‘å…¨é‡å¾®è°ƒçš„æ•ˆæœã€‚
:::

### ä¼ ç»Ÿå¾®è°ƒ vs LoRA

![ä¼ ç»Ÿå¾®è°ƒ vs LoRA](https://media.geeksforgeeks.org/wp-content/uploads/20250614145723026204/Fine-tuned.webp)
*Simple vs Base vs Fine-Tuned Model*

**ä¼ ç»Ÿå¾®è°ƒï¼ˆFull Fine-Tuningï¼‰**ï¼šæ›´æ–°é¢„è®­ç»ƒæ¨¡å‹çš„å…¨éƒ¨æˆ–å¤§éƒ¨åˆ†å‚æ•°ã€‚å¯¹äºæ‹¥æœ‰æ•°åäº¿å‚æ•°çš„æ¨¡å‹ï¼Œè¿™éœ€è¦å¤§é‡ GPU ç®—åŠ›ã€æ˜¾å­˜å’Œæ—¶é—´ï¼Œå¯¹ç¡¬ä»¶è¦æ±‚æé«˜ã€‚

**LoRA å¾®è°ƒ**ï¼šä»…æ›´æ–°æ³¨å…¥çš„ä½ç§©çŸ©é˜µï¼Œå¤§å¹…é™ä½è®¡ç®—å’Œæ˜¾å­˜éœ€æ±‚ã€‚

### LoRA åŸç†

![LoRA Adapter Layer](https://media.geeksforgeeks.org/wp-content/uploads/20250614150242653674/LoRA.webp)
*Adapter Layer in LoRA*

```
åŸå§‹æƒé‡ W (dÃ—k)     LoRAåˆ†è§£
     â”‚                  â”‚
     â”‚           â”Œâ”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”
     â”‚           â”‚             â”‚
     â–¼           â–¼             â–¼
   å†»ç»“        B (dÃ—r)      A (rÃ—k)
     â”‚           â”‚             â”‚
     â”‚           â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
     â”‚                  â”‚
     â–¼                  â–¼
  WÂ·x    +           BÂ·AÂ·x
     â”‚                  â”‚
     â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚
              â–¼
         WÂ·x + BÂ·AÂ·x  (r << d, k)
```

**æ ¸å¿ƒæ€æƒ³**ï¼š
- åœ¨ Transformer çš„æ¯ä¸ªå—ä¸­æ’å…¥å°å‹ Adapter æ¨¡å—
- Adapter ä½¿ç”¨ä½ç§©çŸ©é˜µå®ç°
- å¾®è°ƒæ—¶åªæ›´æ–° Adapter å‚æ•°ï¼Œæ ¸å¿ƒæ¨¡å‹æƒé‡ï¼ˆMulti-Head Attentionã€FFN ç­‰ï¼‰ä¿æŒå†»ç»“
- æƒé‡æ›´æ–°çŸ©é˜µ Î”W åˆ†è§£ä¸ºä¸¤ä¸ªä½ç§©çŸ©é˜µçš„ä¹˜ç§¯ï¼š**Î”W = B Ã— A**

### LoRA æ ¸å¿ƒç‰¹æ€§

| ç‰¹æ€§ | è¯´æ˜ |
|------|------|
| **å‚æ•°é«˜æ•ˆå¾®è°ƒ** | ä»… 0.5-5% å‚æ•°å¯è®­ç»ƒï¼Œå…¶ä½™å†»ç»“ |
| **æ˜¾å­˜æ•ˆç‡** | 1GB æ¨¡å‹ä»…éœ€ 2GB VRAMï¼ˆå…¨é‡å¾®è°ƒéœ€ 16GB+ï¼‰ |
| **å®ç°ç®€å•** | HuggingFace PEFT åº“å¹¿æ³›æ”¯æŒ |
| **ä½è¿‡æ‹Ÿåˆé£é™©** | è®­ç»ƒå‚æ•°å°‘ï¼Œå¯¹å°æ•°æ®é›†å‹å¥½ |
| **æ¨¡å—åŒ–** | Adapter å¯çƒ­æ’æ‹”ï¼Œæ”¯æŒå¤šä»»åŠ¡éƒ¨ç½² |
| **æ— æ¨ç†å»¶è¿Ÿ** | è®­ç»ƒåå¯åˆå¹¶åˆ°ä¸»æ¨¡å‹ï¼Œæ— é¢å¤–æ¨ç†å¼€é”€ |

---

## ğŸ“Š PEFTæ–¹æ³•å¯¹æ¯”

![ä¸‰ç§åœºæ™¯å¯¹æ¯”](https://media.geeksforgeeks.org/wp-content/uploads/20250614150323534116/Scenarios-compared.webp)
*Full Fine-Tuning vs Adapter vs LoRA å‚æ•°é‡å¯¹æ¯”*

| åœºæ™¯ | å¯è®­ç»ƒå‚æ•° | è¯´æ˜ |
|------|-----------|------|
| **Scenario 1: Full Fine-Tuning** | 345Mï¼ˆ100%ï¼‰ | æ›´æ–°æ‰€æœ‰æ¨¡å‹å‚æ•° |
| **Scenario 2: Adapter Tuning** | 24Mï¼ˆ~7%ï¼‰ | æ¯å±‚ 1M Ã— 24 å±‚ |
| **Scenario 3: LoRA** | 12Mï¼ˆ~3.5%ï¼‰ | 0.5M Ã— 12 Ã— 2 çŸ©é˜µ |
| **QLoRA** | æ›´å°‘ | LoRA + 4-bit é‡åŒ– |

| æ–¹æ³• | å‚æ•°é‡ | æ˜¾å­˜éœ€æ±‚ | è®­ç»ƒé€Ÿåº¦ | æ•ˆæœ |
|------|--------|----------|----------|------|
| **å…¨é‡å¾®è°ƒï¼ˆFFTï¼‰** | 100% | æé«˜ | æ…¢ | æœ€ä½³ |
| **LoRA** | <1% | ä½ | å¿« | æ¥è¿‘FFT |
| **QLoRA** | <1% | æä½ | ä¸­ | æ¥è¿‘LoRA |
| **Adapter** | ~3% | ä¸­ | ä¸­ | è‰¯å¥½ |
| **Prefix Tuning** | <1% | ä½ | å¿« | ä¸­ç­‰ |

### LoRA vs QLoRA

| ç‰¹æ€§ | LoRA | QLoRA |
|------|------|-------|
| **åŸºåº§æ¨¡å‹ç²¾åº¦** | FP16/BF16 | 4-bité‡åŒ– |
| **æ˜¾å­˜å ç”¨** | ä¸­ç­‰ | æä½ |
| **è®­ç»ƒé€Ÿåº¦** | å¿« | ç¨æ…¢ |
| **æ•ˆæœ** | æœ€ä½³ | æ¥è¿‘LoRA |
| **é€‚ç”¨åœºæ™¯** | æœ‰GPUèµ„æº | æ¶ˆè´¹çº§æ˜¾å¡ |

---

## ğŸ”§ LoRAå®ç°

### ä½¿ç”¨PEFTåº“

```python
from peft import LoraConfig, get_peft_model, TaskType
from transformers import AutoModelForCausalLM, AutoTokenizer

# 1. åŠ è½½åŸºåº§æ¨¡å‹
model = AutoModelForCausalLM.from_pretrained(
    "meta-llama/Llama-2-7b-hf",
    torch_dtype=torch.float16,
    device_map="auto"
)

# 2. é…ç½®LoRA
lora_config = LoraConfig(
    r=16,                          # ä½ç§©ç»´åº¦
    lora_alpha=32,                 # ç¼©æ”¾å› å­
    target_modules=[               # ç›®æ ‡æ¨¡å—
        "q_proj", "k_proj", "v_proj", "o_proj",
        "gate_proj", "up_proj", "down_proj"
    ],
    lora_dropout=0.05,             # Dropoutæ¯”ä¾‹
    bias="none",                   # ä¸è®­ç»ƒåç½®
    task_type=TaskType.CAUSAL_LM   # ä»»åŠ¡ç±»å‹
)

# 3. åº”ç”¨LoRA
model = get_peft_model(model, lora_config)

# 4. æŸ¥çœ‹å¯è®­ç»ƒå‚æ•°
model.print_trainable_parameters()
# è¾“å‡º: trainable params: 4,194,304 || all params: 6,742,609,920 || trainable%: 0.0622
```

### QLoRAï¼ˆQuantized LoRAï¼‰

QLoRA å°†åŸºåº§æ¨¡å‹ä»¥ **4-bit é‡åŒ–**æ ¼å¼åŠ è½½ï¼Œå¤§å¹…å‡å°‘æ˜¾å­˜å ç”¨ï¼ŒåŒæ—¶ä»¥æ›´é«˜ç²¾åº¦ï¼ˆå¦‚ 16-bitï¼‰è®­ç»ƒ LoRA é€‚é…å™¨ã€‚

**QLoRA æ ¸å¿ƒç‰¹æ€§**ï¼š

| ç‰¹æ€§ | è¯´æ˜ |
|------|------|
| **è¿›ä¸€æ­¥èŠ‚çœæ˜¾å­˜** | ä½¿ç”¨ NF4 é‡åŒ–ä¸»æ¨¡å‹æƒé‡ä¸º 4-bitï¼ŒAdapter ä¿æŒ 16-bit |
| **è¶…ä½èµ„æºéœ€æ±‚** | å¯åœ¨æ¶ˆè´¹çº§ GPU ç”šè‡³ CPU ä¸Šå¾®è°ƒæ•°åäº¿å‚æ•°æ¨¡å‹ï¼ˆ1GB æ¨¡å‹ä»…éœ€ ~0.5GB VRAMï¼‰ |
| **ä¿æŒç²¾åº¦** | æ€§èƒ½ä¸æ ‡å‡† LoRA å’Œå…¨é‡å¾®è°ƒç›¸å½“ï¼ŒæŸå¤±å¯å¿½ç•¥ |
| **Adapter æ”¾ç½®** | å¯¹äºå¤§æ¨¡å‹ï¼Œå»ºè®®å°† LoRA åº”ç”¨äºæ‰€æœ‰çº¿æ€§å±‚ï¼Œä¸ä»…é™äº Q/K/V |
| **åŒé‡é‡åŒ–** | å¯è¿›ä¸€æ­¥å‹ç¼©å­˜å‚¨ï¼Œå°¤å…¶æ˜¯ scale/offset å¸¸é‡ |
| **é‡åŒ–æŸå¤±ç¼“è§£** | LoRA ä½œä¸º"è¡¥å¿å™¨"ä¿®æ­£é‡åŒ–å¼•å…¥çš„è¯¯å·® |

**æƒè¡¡**ï¼šQLoRA å› é‡åŒ–/åé‡åŒ–æ­¥éª¤æ¯” LoRA ç¨æ…¢ï¼Œä½†æ˜¾å­˜èŠ‚çœæ˜¾è‘—ï¼Œæ‰©å±•æ€§æå¼ºã€‚

```python
from transformers import BitsAndBytesConfig
from peft import prepare_model_for_kbit_training

# 1. 4-bité‡åŒ–é…ç½®
bnb_config = BitsAndBytesConfig(
    load_in_4bit=True,
    bnb_4bit_quant_type="nf4",           # NormalFloat4é‡åŒ–
    bnb_4bit_compute_dtype=torch.bfloat16,
    bnb_4bit_use_double_quant=True       # åŒé‡é‡åŒ–
)

# 2. åŠ è½½é‡åŒ–æ¨¡å‹
model = AutoModelForCausalLM.from_pretrained(
    "meta-llama/Llama-2-7b-hf",
    quantization_config=bnb_config,
    device_map="auto"
)

# 3. å‡†å¤‡æ¨¡å‹è¿›è¡Œk-bitè®­ç»ƒ
model = prepare_model_for_kbit_training(model)

# 4. åº”ç”¨LoRAï¼ˆå»ºè®®åº”ç”¨åˆ°æ‰€æœ‰çº¿æ€§å±‚ï¼‰
lora_config = LoraConfig(
    r=16,
    lora_alpha=32,
    target_modules="all-linear",  # å¯¹äº QLoRAï¼Œå»ºè®®åº”ç”¨åˆ°æ‰€æœ‰çº¿æ€§å±‚
    lora_dropout=0.05,
    bias="none",
    task_type=TaskType.CAUSAL_LM
)
model = get_peft_model(model, lora_config)
```

---

## âš™ï¸ å…³é”®è¶…å‚æ•°

### rï¼ˆç§©ï¼‰

| rå€¼ | å‚æ•°é‡ | æ•ˆæœ | å»ºè®®åœºæ™¯ |
|-----|--------|------|----------|
| 4 | æœ€å°‘ | å¤Ÿç”¨ | ç®€å•ä»»åŠ¡ |
| 8 | è¾ƒå°‘ | è‰¯å¥½ | ä¸€èˆ¬ä»»åŠ¡ |
| 16 | ä¸­ç­‰ | å¾ˆå¥½ | å¤æ‚ä»»åŠ¡ï¼ˆæ¨èï¼‰ |
| 32 | è¾ƒå¤š | æœ€ä½³ | è¿½æ±‚æè‡´æ•ˆæœ |
| 64+ | å¾ˆå¤š | é¥±å’Œ | é€šå¸¸ä¸å¿…è¦ |

### lora_alpha

```python
# å®é™…ç¼©æ”¾å› å­ = lora_alpha / r
# å¸¸ç”¨é…ç½®ï¼šlora_alpha = 2 * r

lora_config = LoraConfig(
    r=16,
    lora_alpha=32,  # ç¼©æ”¾å› å­2
    # ...
)
```

### target_modules

| æ¨¡å‹ | æ¨èç›®æ ‡æ¨¡å— |
|------|-------------|
| **LLaMA/Qwen** | q_proj, k_proj, v_proj, o_proj, gate_proj, up_proj, down_proj |
| **GPT-2** | c_attn, c_proj, c_fc |
| **BLOOM** | query_key_value, dense, dense_h_to_4h, dense_4h_to_h |

```python
# è‡ªåŠ¨æ£€æµ‹æ‰€æœ‰çº¿æ€§å±‚
from peft.utils import TRANSFORMERS_MODELS_TO_LORA_TARGET_MODULES_MAPPING

# æˆ–æ‰‹åŠ¨æŒ‡å®š
target_modules = ["q_proj", "v_proj"]  # æœ€å°é…ç½®
target_modules = "all-linear"          # æ‰€æœ‰çº¿æ€§å±‚
```

---

## ğŸ“ˆ è®­ç»ƒæµç¨‹

### å®Œæ•´è®­ç»ƒè„šæœ¬

```python
from transformers import TrainingArguments
from trl import SFTTrainer

# è®­ç»ƒå‚æ•°
training_args = TrainingArguments(
    output_dir="./lora_output",
    num_train_epochs=3,
    per_device_train_batch_size=4,
    gradient_accumulation_steps=4,
    learning_rate=2e-4,              # LoRAé€šå¸¸ç”¨æ›´é«˜å­¦ä¹ ç‡
    warmup_ratio=0.03,
    logging_steps=10,
    save_strategy="epoch",
    fp16=True,
    optim="paged_adamw_8bit",        # 8-bitä¼˜åŒ–å™¨èŠ‚çœæ˜¾å­˜
    gradient_checkpointing=True,      # æ¢¯åº¦æ£€æŸ¥ç‚¹
)

# åˆ›å»ºè®­ç»ƒå™¨
trainer = SFTTrainer(
    model=model,
    args=training_args,
    train_dataset=dataset,
    peft_config=lora_config,
    max_seq_length=2048,
)

# å¼€å§‹è®­ç»ƒ
trainer.train()

# ä¿å­˜LoRAæƒé‡
model.save_pretrained("./lora_weights")
```

### åˆå¹¶æƒé‡

```python
from peft import PeftModel

# åŠ è½½åŸºåº§æ¨¡å‹
base_model = AutoModelForCausalLM.from_pretrained("meta-llama/Llama-2-7b-hf")

# åŠ è½½LoRAæƒé‡
model = PeftModel.from_pretrained(base_model, "./lora_weights")

# åˆå¹¶æƒé‡
merged_model = model.merge_and_unload()

# ä¿å­˜å®Œæ•´æ¨¡å‹
merged_model.save_pretrained("./merged_model")
```

---

## ğŸ¯ æœ€ä½³å®è·µ

### æ˜¾å­˜ä¼˜åŒ–

```python
# 1. ä½¿ç”¨æ¢¯åº¦æ£€æŸ¥ç‚¹
model.gradient_checkpointing_enable()

# 2. ä½¿ç”¨8-bitä¼˜åŒ–å™¨
training_args = TrainingArguments(
    optim="paged_adamw_8bit",
    # ...
)

# 3. ä½¿ç”¨Flash Attentionï¼ˆå¦‚æœæ”¯æŒï¼‰
model = AutoModelForCausalLM.from_pretrained(
    model_name,
    attn_implementation="flash_attention_2"
)
```

### å¤šLoRAé€‚é…å™¨

```python
from peft import PeftModel

# åŠ è½½åŸºåº§æ¨¡å‹
base_model = AutoModelForCausalLM.from_pretrained("base_model")

# åŠ è½½å¤šä¸ªLoRAé€‚é…å™¨
model = PeftModel.from_pretrained(base_model, "lora_adapter_1")
model.load_adapter("lora_adapter_2", adapter_name="adapter2")

# åˆ‡æ¢é€‚é…å™¨
model.set_adapter("adapter2")

# æˆ–åˆå¹¶å¤šä¸ªé€‚é…å™¨
model.add_weighted_adapter(
    adapters=["default", "adapter2"],
    weights=[0.7, 0.3],
    adapter_name="merged"
)
```

---

## ï¿½ æ€§èƒ½åŸºå‡†ä¸å‘ç°

### LoRA vs å…¨é‡å¾®è°ƒ

| ç»´åº¦ | LoRA | å…¨é‡å¾®è°ƒ |
|------|------|----------|
| **å‚æ•°é‡** | 0.2-0.3% | 100% |
| **GLUE åˆ†æ•°** | ä¸å…¨é‡å¾®è°ƒå·®è· < 1% | æœ€ä½³ |
| **æ˜¾å­˜å ç”¨** | é™ä½ **70%** | åŸºå‡† |
| **é€‚ç”¨åœºæ™¯** | æ–‡æœ¬åˆ†ç±»ã€æ‘˜è¦ã€é—®ç­”ç­‰ | å¤æ‚é¢†åŸŸï¼ˆæ•°å­¦ã€ç¼–ç¨‹ï¼‰ |

**å‘ç°**ï¼š
- LoRA åœ¨å¤§å¤šæ•°ä»»åŠ¡ä¸Šè¾¾åˆ°ä¸å…¨é‡å¾®è°ƒ**ç›¸å½“çš„æ€§èƒ½**
- å…¨é‡å¾®è°ƒåœ¨å¤æ‚é¢†åŸŸï¼ˆå¦‚æ•°å­¦ã€ç¼–ç¨‹ï¼‰ä»æœ‰ä¼˜åŠ¿ï¼Œä½†å·®è·å¯é€šè¿‡è¶…å‚æ•°è°ƒä¼˜ç¼©å°
- LoRA æ˜¾å­˜é™ä½ 70%ï¼Œå¯åœ¨æ¶ˆè´¹çº§ GPU ä¸Šéƒ¨ç½²

### Adapter æ•ˆç‡æƒè¡¡

| ç»´åº¦ | Adapter | è¯´æ˜ |
|------|---------|------|
| **ç²¾åº¦** | ä¸å…¨é‡å¾®è°ƒç›¸å½“ | é€‚ç”¨äºæƒ…æ„Ÿåˆ†æã€æ³•å¾‹æ–‡æ¡£å¤„ç†ç­‰ |
| **æ¨ç†å»¶è¿Ÿ** | å¢åŠ  10-20% | å› é¢å¤–å±‚å¤„ç† |
| **è®¡ç®—éœ€æ±‚** | å¤§å¹…é™ä½ | é€‚åˆèµ„æºå—é™ç¯å¢ƒ |

---

## ï¿½ğŸ”— ç›¸å…³é˜…è¯»

- [è®­ç»ƒå¾®è°ƒæ¦‚è¿°](/llms/training/) - äº†è§£å®Œæ•´è®­ç»ƒæµç¨‹
- [SFTç›‘ç£å¾®è°ƒ](/llms/training/sft) - LoRAå¸¸ç”¨äºSFT
- [æ•°æ®å¤„ç†](/llms/training/data) - å‡†å¤‡è®­ç»ƒæ•°æ®

> **ç›¸å…³æ–‡ç« **ï¼š
> - [Fine-Tuning using LoRA and QLoRA - GeeksforGeeks](https://www.geeksforgeeks.org/deep-learning/fine-tuning-using-lora-and-qlora/)
> - [å¤§æ¨¡å‹å¾®è°ƒçš„"çœé’±"ç§˜ç¬ˆï¼šPEFTæŠ€æœ¯æ·±åº¦è§£æ](https://dd-ff.blog.csdn.net/article/details/153965724)
> - [Genesis-LLMå…¨æµç¨‹å¼€æºé¡¹ç›®è§£æ](https://dd-ff.blog.csdn.net/article/details/155355144)

> **å¤–éƒ¨èµ„æº**ï¼š
> - [LoRAåŸå§‹è®ºæ–‡](https://arxiv.org/abs/2106.09685)
> - [PEFTåº“æ–‡æ¡£](https://huggingface.co/docs/peft)
> - [QLoRAè®ºæ–‡](https://arxiv.org/abs/2305.14314)
