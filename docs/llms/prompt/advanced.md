---
title: é«˜çº§æç¤ºæŠ€æœ¯
description: ReActã€æ€ç»´æ ‘ã€è‡ªæˆ‘åæ€ç­‰é«˜çº§æŠ€æœ¯
---

# é«˜çº§æç¤ºæŠ€æœ¯

> å¤æ‚ä»»åŠ¡çš„æç¤ºè¯ç­–ç•¥â€”â€”ä»Žæ‰‹åŠ¨æŽ¨ç†å¼•å¯¼åˆ°åŽŸç”ŸæŽ¨ç†è°ƒç”¨

## âš ï¸ é‡è¦æç¤ºï¼šæŽ¨ç†æ¨¡åž‹çš„èŒƒå¼è½¬å˜

åœ¨å­¦ä¹ é«˜çº§æç¤ºæŠ€æœ¯å‰ï¼Œéœ€è¦ç†è§£**AIæ¨¡åž‹çš„"å¤§åˆ†æµ"**ï¼š

| æ¨¡åž‹ç±»åž‹ | ä»£è¡¨ | CoTç­‰æŠ€å·§ | æœ€ä½³ç­–ç•¥ |
|----------|------|-----------|----------|
| **ç³»ç»Ÿ1æ¨¡åž‹** | GPT-4o | âœ… æœ‰æ•ˆ | ä½¿ç”¨CoTã€ReActç­‰æŠ€å·§å¼•å¯¼æŽ¨ç† |
| **ç³»ç»Ÿ2æ¨¡åž‹** | o1/o3 | âŒ åè€Œæœ‰å®³ | ç®€æ´ç›´æŽ¥çš„æŒ‡ä»¤ï¼Œä¿¡ä»»åŽŸç”ŸæŽ¨ç† |

::: warning å…³é”®åŒºåˆ«
å¯¹äºŽGPT-4oç­‰ä¼ ç»Ÿæ¨¡åž‹ï¼ŒCoTç­‰æŠ€æœ¯æ˜¯**æ¨¡æ‹Ÿ**"ç³»ç»Ÿ2"æ€è€ƒã€‚  
å¯¹äºŽo1ç­‰æŽ¨ç†æ¨¡åž‹ï¼ŒæŽ¨ç†æ˜¯**åŽŸç”Ÿ**èƒ½åŠ›ï¼Œå¤–éƒ¨CoTæç¤ºä¼š**å¹²æ‰°**å…¶å†…éƒ¨æ›´ä¼˜çš„æŽ¨ç†è¿‡ç¨‹ã€‚
:::

---

## ðŸ”„ ReActï¼ˆæŽ¨ç†+è¡ŒåŠ¨ï¼‰

### æ¦‚å¿µ

ç»“åˆæŽ¨ç†ï¼ˆReasoningï¼‰å’Œè¡ŒåŠ¨ï¼ˆActingï¼‰ï¼Œè®©æ¨¡åž‹åœ¨æ€è€ƒå’Œæ‰§è¡Œä¹‹é—´äº¤æ›¿ã€‚

```
é—®é¢˜ï¼šè‹¹æžœå…¬å¸CEOæ˜¯è°ï¼Ÿä»–å‡ºç”Ÿåœ¨å“ªä¸€å¹´ï¼Ÿ

Thought 1: æˆ‘éœ€è¦å…ˆæŸ¥æ‰¾è‹¹æžœå…¬å¸çš„CEO
Action 1: Search("Apple Inc. current CEO")
Observation 1: Tim Cook is the CEO of Apple Inc.

Thought 2: çŽ°åœ¨æˆ‘çŸ¥é“CEOæ˜¯Tim Cookï¼Œéœ€è¦æŸ¥æ‰¾ä»–çš„å‡ºç”Ÿå¹´ä»½
Action 2: Search("Tim Cook birth year")
Observation 2: Tim Cook was born on November 1, 1960.

Thought 3: æˆ‘å·²èŽ·å¾—æ‰€æœ‰ä¿¡æ¯
Final Answer: è‹¹æžœå…¬å¸CEOæ˜¯Tim Cookï¼Œä»–å‡ºç”ŸäºŽ1960å¹´ã€‚
```

### ReActå®žçŽ°

```python
REACT_PROMPT = """
å›žç­”ä»¥ä¸‹é—®é¢˜ï¼Œä½¿ç”¨Thought/Action/Observationæ ¼å¼ï¼š

å¯ç”¨å·¥å…·ï¼š
- Search(query): æœç´¢ä¿¡æ¯
- Calculator(expression): è®¡ç®—æ•°å­¦è¡¨è¾¾å¼

é—®é¢˜ï¼š{question}

Thought 1:"""

def react_loop(question: str, max_steps: int = 5):
    """ReActæŽ¨ç†å¾ªçŽ¯"""
    prompt = REACT_PROMPT.format(question=question)
    
    for step in range(max_steps):
        response = llm.generate(prompt)
        
        if "Final Answer:" in response:
            return extract_answer(response)
        
        # è§£æžAction
        action = parse_action(response)
        
        # æ‰§è¡ŒAction
        observation = execute_action(action)
        
        # æ›´æ–°æç¤º
        prompt += response + f"\nObservation {step+1}: {observation}\n\nThought {step+2}:"
    
    return "æ— æ³•å¾—å‡ºç»“è®º"
```

---

## ðŸŒ³ æ€ç»´æ ‘ï¼ˆTree of Thoughtsï¼‰

### æ¦‚å¿µ

æŽ¢ç´¢å¤šä¸ªæŽ¨ç†è·¯å¾„ï¼Œé€‰æ‹©æœ€ä¼˜è§£ã€‚

```
é—®é¢˜ï¼š24ç‚¹æ¸¸æˆ - ç”¨ 1, 2, 3, 4 ç»„æˆ24

â”Œâ”€ è·¯å¾„1: (1+2+3)*4 = 24 âœ“
â”‚
â”œâ”€ è·¯å¾„2: (1+3)*(2+4) = 24 âœ“
â”‚
â”œâ”€ è·¯å¾„3: 1*2*3*4 = 24 âœ“
â”‚
â””â”€ è·¯å¾„4: (4-1)*(2+3+1) = ? âœ— ä¸å¯¹
```

### ToTå®žçŽ°

```python
def tree_of_thoughts(problem: str, branching: int = 3, depth: int = 3):
    """æ€ç»´æ ‘æœç´¢"""
    
    def generate_thoughts(state: str) -> list:
        """ç”Ÿæˆå¤šä¸ªæ€è€ƒåˆ†æ”¯"""
        prompt = f"""
é—®é¢˜ï¼š{problem}
å½“å‰çŠ¶æ€ï¼š{state}

è¯·ç”Ÿæˆ{branching}ä¸ªä¸åŒçš„ä¸‹ä¸€æ­¥æ€è€ƒï¼Œæ¯è¡Œä¸€ä¸ªï¼š
"""
        response = llm.generate(prompt)
        return response.strip().split('\n')
    
    def evaluate_thought(thought: str) -> float:
        """è¯„ä¼°æ€è€ƒçš„è´¨é‡"""
        prompt = f"""
é—®é¢˜ï¼š{problem}
æ€è€ƒæ­¥éª¤ï¼š{thought}

è¯·è¯„ä¼°è¿™ä¸ªæ€è€ƒæ˜¯å¦æœ‰åŠ©äºŽè§£å†³é—®é¢˜ï¼Œè¿”å›ž0-1ä¹‹é—´çš„åˆ†æ•°ï¼š
"""
        score = float(llm.generate(prompt))
        return score
    
    # BFSæœç´¢
    queue = [("", 0)]  # (state, depth)
    best_solution = None
    
    while queue:
        state, d = queue.pop(0)
        
        if d >= depth:
            continue
        
        thoughts = generate_thoughts(state)
        
        for thought in thoughts:
            score = evaluate_thought(thought)
            new_state = state + "\n" + thought
            
            if is_solution(new_state, problem):
                if best_solution is None or score > best_solution[1]:
                    best_solution = (new_state, score)
            else:
                queue.append((new_state, d + 1))
    
    return best_solution
```

---

## ðŸ” è‡ªæˆ‘åæ€ï¼ˆSelf-Reflectionï¼‰

### æ¦‚å¿µ

è®©æ¨¡åž‹æ‰¹è¯„å’Œæ”¹è¿›è‡ªå·±çš„è¾“å‡ºã€‚

```
ç¬¬ä¸€æ¬¡å›žç­”ï¼š
Pythonæ˜¯ä¸€ç§ç¼–ç¨‹è¯­è¨€ã€‚

è‡ªæˆ‘åæ€ï¼š
è¿™ä¸ªå›žç­”å¤ªç®€çŸ­äº†ï¼Œæ²¡æœ‰æä¾›æœ‰ç”¨çš„ä¿¡æ¯ã€‚åº”è¯¥åŒ…æ‹¬ï¼š
- Pythonçš„ç‰¹ç‚¹
- ä¸»è¦åº”ç”¨åœºæ™¯
- å­¦ä¹ å»ºè®®

æ”¹è¿›åŽçš„å›žç­”ï¼š
Pythonæ˜¯ä¸€ç§é«˜çº§ã€è§£é‡Šåž‹ç¼–ç¨‹è¯­è¨€ï¼Œä»¥ç®€æ´æ˜“è¯»è‘—ç§°ã€‚
ä¸»è¦åº”ç”¨äºŽWebå¼€å‘ã€æ•°æ®åˆ†æžã€æœºå™¨å­¦ä¹ ã€è‡ªåŠ¨åŒ–è„šæœ¬ç­‰é¢†åŸŸã€‚
å¯¹åˆå­¦è€…å‹å¥½ï¼Œæ˜¯å…¥é—¨ç¼–ç¨‹çš„é¦–é€‰è¯­è¨€ã€‚
```

### å®žçŽ°

```python
def self_reflect(question: str, max_iterations: int = 3) -> str:
    """è‡ªæˆ‘åæ€æ”¹è¿›"""
    
    # åˆå§‹å›žç­”
    response = llm.generate(f"è¯·å›žç­”ï¼š{question}")
    
    for i in range(max_iterations):
        # è‡ªæˆ‘æ‰¹è¯„
        critique = llm.generate(f"""
è¯·æ‰¹è¯„ä»¥ä¸‹å›žç­”çš„ä¸è¶³ä¹‹å¤„ï¼š

é—®é¢˜ï¼š{question}
å›žç­”ï¼š{response}

éœ€è¦æ”¹è¿›çš„åœ°æ–¹ï¼š""")
        
        # æ£€æŸ¥æ˜¯å¦æ»¡æ„
        if "æ²¡æœ‰æ˜Žæ˜¾é—®é¢˜" in critique or "å›žç­”å®Œæ•´" in critique:
            break
        
        # æ”¹è¿›å›žç­”
        response = llm.generate(f"""
æ ¹æ®æ‰¹è¯„æ”¹è¿›å›žç­”ï¼š

é—®é¢˜ï¼š{question}
åŽŸå›žç­”ï¼š{response}
æ‰¹è¯„ï¼š{critique}

æ”¹è¿›åŽçš„å›žç­”ï¼š""")
    
    return response
```

---

## ðŸ“Š ç»“æž„åŒ–è¾“å‡º

### JSONè¾“å‡º

```python
STRUCTURED_PROMPT = """
è¯·åˆ†æžä»¥ä¸‹æ–‡æœ¬çš„æƒ…æ„Ÿï¼Œè¿”å›žJSONæ ¼å¼ï¼š

æ–‡æœ¬ï¼š{text}

è¿”å›žæ ¼å¼ï¼š
{{
  "sentiment": "positive/negative/neutral",
  "confidence": 0.0-1.0,
  "keywords": ["å…³é”®è¯1", "å…³é”®è¯2"],
  "summary": "ä¸€å¥è¯æ€»ç»“"
}}
"""

# ä½¿ç”¨OpenAIçš„JSONæ¨¡å¼
response = openai.chat.completions.create(
    model="gpt-4-turbo",
    messages=[{"role": "user", "content": prompt}],
    response_format={"type": "json_object"}
)
```

### Pydanticç»“æž„åŒ–

```python
from pydantic import BaseModel
from openai import OpenAI

class SentimentResult(BaseModel):
    sentiment: str
    confidence: float
    keywords: list[str]
    summary: str

client = OpenAI()

response = client.beta.chat.completions.parse(
    model="gpt-4o",
    messages=[{"role": "user", "content": prompt}],
    response_format=SentimentResult
)

result: SentimentResult = response.choices[0].message.parsed
```

---

## ðŸŽ­ å¤šè§’è‰²è®¨è®º

### æ¦‚å¿µ

æ¨¡æ‹Ÿå¤šä¸ªè§’è‰²è®¨è®ºï¼ŒèŽ·å¾—æ›´å…¨é¢çš„è§‚ç‚¹ã€‚

```python
MULTI_ROLE_PROMPT = """
è¯·æ¨¡æ‹Ÿä¸‰ä½ä¸“å®¶è®¨è®ºä»¥ä¸‹é—®é¢˜ï¼š

é—®é¢˜ï¼š{question}

ä¸“å®¶Aï¼ˆæ”¯æŒè€…ï¼‰ï¼š
[é˜è¿°æ”¯æŒè§‚ç‚¹]

ä¸“å®¶Bï¼ˆåå¯¹è€…ï¼‰ï¼š
[é˜è¿°åå¯¹è§‚ç‚¹]

ä¸“å®¶Cï¼ˆä¸­ç«‹è€…ï¼‰ï¼š
[ç»¼åˆåˆ†æžï¼Œç»™å‡ºå¹³è¡¡ç»“è®º]

æœ€ç»ˆç»“è®ºï¼š
[åŸºäºŽè®¨è®ºçš„ç»¼åˆç­”æ¡ˆ]
"""
```

---

## ðŸ§  æŽ¨ç†æ¨¡åž‹æœ€ä½³å®žè·µ

### ä½•æ—¶ä½¿ç”¨æŽ¨ç†æ¨¡åž‹

| åœºæ™¯ | æŽ¨èæ¨¡åž‹ | åŽŸå›  |
|------|----------|------|
| **æ•°å­¦æŽ¨ç†** | o1/o3 | åŽŸç”Ÿå¼ºæŽ¨ç†èƒ½åŠ› |
| **ä»£ç è°ƒè¯•** | o1/o3 | å¤šæ­¥é€»è¾‘åˆ†æž |
| **å¤æ‚è§„åˆ’** | o1/o3 | åˆ†è§£å’Œåè°ƒèƒ½åŠ› |
| **èŠå¤©å¯¹è¯** | GPT-4o | é€Ÿåº¦å¿«ã€æˆæœ¬ä½Ž |
| **åˆ›æ„å†™ä½œ** | GPT-4o | çµæ´»æ€§å’Œå¤šæ ·æ€§ |
| **å®žæ—¶äº¤äº’** | GPT-4o | ä½Žå»¶è¿Ÿè¦æ±‚ |

### o-ç³»åˆ—æç¤ºæŠ€å·§

```python
# âŒ é”™è¯¯ï¼šä½¿ç”¨CoTæç¤º
bad_prompt = """
è¯·ä¸€æ­¥ä¸€æ­¥æ€è€ƒè¿™ä¸ªé—®é¢˜ï¼š
1. é¦–å…ˆåˆ†æžé—®é¢˜çš„æ¡ä»¶
2. ç„¶åŽåˆ—å‡ºå¯èƒ½çš„è§£å†³æ–¹æ¡ˆ
3. æœ€åŽé€‰æ‹©æœ€ä¼˜è§£

é—®é¢˜ï¼šå¦‚ä½•è®¾è®¡ä¸€ä¸ªåˆ†å¸ƒå¼ç¼“å­˜ç³»ç»Ÿï¼Ÿ
"""

# âœ… æ­£ç¡®ï¼šç®€æ´ç›´æŽ¥
good_prompt = """
è®¾è®¡ä¸€ä¸ªåˆ†å¸ƒå¼ç¼“å­˜ç³»ç»Ÿã€‚

è¦æ±‚ï¼š
- æ”¯æŒç™¾ä¸‡çº§QPS
- 99.9%å¯ç”¨æ€§
- æ•°æ®ä¸€è‡´æ€§ä¿éšœ

è¯·ç»™å‡ºè¯¦ç»†çš„æž¶æž„è®¾è®¡ã€‚
"""

# âœ… ä½¿ç”¨developeræ¶ˆæ¯ï¼ˆæ›¿ä»£systemæ¶ˆæ¯ï¼‰
messages = [
    {"role": "developer", "content": "ä½ æ˜¯åˆ†å¸ƒå¼ç³»ç»Ÿæž¶æž„ä¸“å®¶"},
    {"role": "user", "content": good_prompt}
]
```

### æ··åˆæž¶æž„ï¼šè§„åˆ’è€…+æ‰§è¡Œè€…

```python
class HybridReasoningSystem:
    """æ··åˆæŽ¨ç†ç³»ç»Ÿï¼šo1è§„åˆ’ + GPT-4oæ‰§è¡Œ"""
    
    def __init__(self):
        self.planner = "o1"  # è§„åˆ’è€…
        self.executor = "gpt-4o"  # æ‰§è¡Œè€…
    
    async def solve_complex_task(self, task: str):
        # 1. è§„åˆ’è€…åˆ¶å®šè®¡åˆ’ï¼ˆä½¿ç”¨ç®€æ´æç¤ºï¼‰
        plan = await self.call_model(
            model=self.planner,
            prompt=f"å°†ä»¥ä¸‹ä»»åŠ¡åˆ†è§£ä¸ºå…·ä½“æ­¥éª¤ï¼š{task}"
        )
        
        # 2. è§£æžè®¡åˆ’æ­¥éª¤
        steps = self.parse_steps(plan)
        
        # 3. æ‰§è¡Œè€…é€æ­¥æ‰§è¡Œ
        results = []
        for step in steps:
            result = await self.call_model(
                model=self.executor,
                prompt=step
            )
            results.append(result)
        
        # 4. æ•´åˆç»“æžœ
        return self.synthesize_results(results)
```

---

## ðŸ”— ç›¸å…³é˜…è¯»

- [åŸºç¡€æç¤ºæŠ€æœ¯](/llms/prompt/basics) - Zero-shotã€Few-shot
- [ä¸Šä¸‹æ–‡å·¥ç¨‹](/llms/prompt/context) - åŠ¨æ€ä¸Šä¸‹æ–‡ç®¡ç†
- [æç¤ºå·¥ç¨‹å…¨æ™¯](/llms/prompt/) - å®Œæ•´æŠ€æœ¯æž¶æž„
- [Agentè§„åˆ’](/llms/agent/planning) - ReActåœ¨Agentä¸­çš„åº”ç”¨

> **ç›¸å…³è®ºæ–‡**ï¼š
> - [ReAct](https://arxiv.org/abs/2210.03629)
> - [Tree of Thoughts](https://arxiv.org/abs/2305.10601)
> - [Self-Refine](https://arxiv.org/abs/2303.17651)

> **ç›¸å…³æ–‡ç« **ï¼š
> - [æŽŒæ¡AIæŽ¨ç†ï¼šä»Ž"æç¤ºå·¥ç¨‹"åˆ°"æŽ¨ç†æž¶æž„"](https://dd-ff.blog.csdn.net/article/details/154479954)
> - [ä»ŽæŒ‡ä»¤åˆ°æ™ºèƒ½ï¼šæç¤ºè¯ä¸Žä¸Šä¸‹æ–‡å·¥ç¨‹](https://dd-ff.blog.csdn.net/article/details/152799914)
> - [OpenAI Prompt Engineeringä¸ŽPrompt Cachingå®žæˆ˜](https://dd-ff.blog.csdn.net/article/details/154450002)
