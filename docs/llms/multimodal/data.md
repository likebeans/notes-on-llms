---
title: æ•°æ®å·¥ç¨‹
description: LAION-5B æ¸…æ´—ã€ShareGPT4V åˆæˆä¸åŠ¨æ€åˆ†è¾¨ç‡å¤„ç†
---

# å¤šæ¨¡æ€æ•°æ®å·¥ç¨?

> **"Data is the new oil"** â€”â€?åœ¨å¤šæ¨¡æ€é¢†åŸŸï¼Œæ•°æ®çš„è´¨é‡ä¸è§„æ¨¡ç›´æ¥å†³å®šæ¨¡å‹ä¸Šé™ã€‚æ•°æ®å·¥ç¨‹ä¸ä»…æ˜¯æ”¶é›†ï¼Œæ›´æ¶‰åŠå¤æ‚çš„æ¸…æ´—ã€è¿‡æ»¤ä¸åˆæˆç­–ç•¥ã€?

---

## æ•°æ®å·¥ç¨‹å…¨æ™¯

```mermaid
flowchart LR
    subgraph æ•°æ®æº?
        WEB[ç½‘ç»œçˆ¬å–]
        HUMAN[äººå·¥æ ‡æ³¨]
        SYNTH[æ¨¡å‹åˆæˆ]
    end
    
    subgraph å¤„ç†æµç¨‹
        CLEAN[æ¸…æ´—è¿‡æ»¤]
        ALIGN[å›¾æ–‡å¯¹é½]
        FORMAT[æ ¼å¼è½¬æ¢]
    end
    
    subgraph è¾“å‡º
        PT[é¢„è®­ç»ƒæ•°æ®]
        SFT[å¾®è°ƒæ•°æ®]
        EVAL[è¯„æµ‹æ•°æ®]
    end
    
    WEB --> CLEAN
    HUMAN --> ALIGN
    SYNTH --> FORMAT
    CLEAN --> PT
    ALIGN --> SFT
    FORMAT --> EVAL
```

---

## LAION-5Bï¼šå·¥ä¸šçº§æ•°æ®æ¸…æ´—

LAION-5B æ˜¯ç›®å‰æœ€å¤§çš„å¼€æºå¤šæ¨¡æ€æ•°æ®é›†ï¼ŒåŒ…å?**58.5 äº?*å›¾æ–‡å¯¹ã€?

### æ„å»ºæµæ°´çº?

```mermaid
flowchart LR
    CC[Common Crawl] --> PARSE[HTML è§£æ]
    PARSE --> EXTRACT[æå– img+alt]
    EXTRACT --> DOWNLOAD[ä¸‹è½½å›¾åƒ]
    DOWNLOAD --> CLIP[CLIP è¿‡æ»¤]
    CLIP --> DEDUP[å»é‡]
    DEDUP --> NSFW[NSFW è¿‡æ»¤]
    NSFW --> OUT[LAION-5B]
```

### å…³é”®è¿‡æ»¤æ­¥éª¤

| æ­¥éª¤ | æŠ€æœ?| ç›®çš„ |
| :--- | :--- | :--- |
| **URL è¿‡æ»¤** | é»‘åå•åŒ¹é…?| æ’é™¤ä½è´¨/è¿è§„ç«™ç‚¹ |
| **å›¾åƒä¸‹è½½** | å¹¶è¡Œçˆ¬å– + é‡è¯• | è·å–åŸå§‹å›¾åƒ |
| **CLIP è¿‡æ»¤** | è®¡ç®—å›¾æ–‡ç›¸ä¼¼åº?| ä¿è¯è¯­ä¹‰ç›¸å…³æ€?|
| **å»é‡** | æ„ŸçŸ¥å“ˆå¸Œ (pHash) | å»é™¤é‡å¤å›¾åƒ |
| **NSFW è¿‡æ»¤** | CLIP åˆ†ç±»å™?| è¿‡æ»¤æˆäººå†…å®¹ |

### CLIP Score é˜ˆå€?

```python
# LAION è¿‡æ»¤é€»è¾‘
def filter_sample(image, text):
    image_emb = clip.encode_image(image)
    text_emb = clip.encode_text(text)
    score = cosine_similarity(image_emb, text_emb)
    
    # è‹±æ–‡æ•°æ®é˜ˆå€?
    if language == 'en':
        return score >= 0.28
    # å¤šè¯­è¨€æ•°æ®é˜ˆå€?
    else:
        return score >= 0.26
```

### CLIP è¿‡æ»¤çš„åŒåˆƒå‰‘

<div class="compare-box">
  <div class="compare-item highlight">
    <div class="compare-title">ä¼˜åŠ¿</div>
    <p class="compare-desc">âœ?ä¿è¯å›¾æ–‡è¯­ä¹‰ç›¸å…³ - âœ?è‡ªåŠ¨è¿‡æ»¤ä½è´¨æ•°æ® - âœ?å¯å¤§è§„æ¨¡å¹¶è¡Œå¤„ç†</p>
  </div>
  <div class="compare-vs">VS</div>
  <div class="compare-item">
    <div class="compare-title">åŠ£åŠ¿</div>
    <p class="compare-desc">â?ç»§æ‰¿ CLIP åè§ - â?è¿‡æ»¤ç½•è§æ¦‚å¿µ - â?æŸäº›è‰ºæœ¯é£æ ¼è¢«æ’é™?/p>
  </div>
</div>

::: warning CLIP åè§ä¼ æ’­
å¦‚æœ CLIP æ— æ³•è¯†åˆ«æŸç§è‰ºæœ¯é£æ ¼æˆ–ç”Ÿåƒ»æ¦‚å¿µï¼Œç›¸å…³æ•°æ®å°±ä¼šè¢«è¿‡æ»¤æ‰ã€‚è¿™å¯¼è‡´ä¸‹æ¸¸æ¨¡å‹åœ¨è¿™äº›é¢†åŸŸè¦†ç›–ç‡ä¸è¶³ï¼Œå½¢æˆ?åè§é—­ç¯"ã€?
:::

### LAION æ•°æ®é›†å®¶æ—?

| æ•°æ®é›?| è§„æ¨¡ | è¯­è¨€ | ç‰¹ç‚¹ |
| :--- | :--- | :--- | :--- |
| **LAION-400M** | 4 äº?| è‹±æ–‡ | æ—©æœŸç‰ˆæœ¬ |
| **LAION-5B** | 58.5 äº?| å¤šè¯­è¨€ | ä¸»åŠ›æ•°æ®é›?|
| **LAION-Aesthetic** | 1.2 äº?| è‹±æ–‡ | é«˜ç¾å­¦è¯„åˆ?|
| **LAION-COCO** | 6 äº?| è‹±æ–‡ | ç±?COCO æ ¼å¼ |

---

## ShareGPT4Vï¼šé«˜è´¨é‡ Caption åˆæˆ

ä¼ ç»Ÿç½‘ç»œçˆ¬å–æ•°æ®çš?alt æ–‡æœ¬å¾€å¾€**è¿‡äºç®€çŸ?*ï¼Œç¼ºä¹å¯¹å›¾åƒç»†èŠ‚çš„æè¿°ã€?

### é—®é¢˜ç¤ºä¾‹

| æ¥æº | Caption ç¤ºä¾‹ |
| :--- | :--- |
| **ç½‘ç»œ alt æ–‡æœ¬** | "beach photo" |
| **äººå·¥æ ‡æ³¨** | "A person surfing on a wave" |
| **GPT-4V ç”Ÿæˆ** | "The image captures an exhilarating moment of a surfer riding a powerful wave. The surfer, clad in a black wetsuit, demonstrates remarkable balance and skill..." |

### ShareGPT4V æ•°æ®é—­ç¯

```mermaid
flowchart TB
    subgraph "Step 1: ç§å­æ•°æ®"
        IMG1[10ä¸‡é«˜è´¨é‡å›¾ç‰‡]
        GPT4V[GPT-4V]
        IMG1 --> GPT4V
        GPT4V --> SEED[10ä¸‡è¯¦å°½æè¿°]
    end
    
    subgraph "Step 2: è®­ç»ƒ Captioner"
        SEED --> TRAIN[è®­ç»ƒ Share-Captioner]
        BASE[åŸºåº§æ¨¡å‹] --> TRAIN
        TRAIN --> CAP[Share-Captioner]
    end
    
    subgraph "Step 3: å¤§è§„æ¨¡æ ‡æ³?
        IMG2[120ä¸‡å›¾ç‰‡]
        CAP --> LABEL[é‡æ–°æ ‡æ³¨]
        IMG2 --> LABEL
        LABEL --> DATA[ShareGPT4V æ•°æ®é›†]
    end
```

### GPT-4V Prompt è®¾è®¡

```markdown
è¯·è¯¦ç»†æè¿°è¿™å¼ å›¾ç‰‡ï¼ŒåŒ…æ‹¬ä½†ä¸é™äºï¼?
1. ä¸»è¦å¯¹è±¡åŠå…¶å±æ€§ï¼ˆé¢œè‰²ã€å½¢çŠ¶ã€å¤§å°ï¼‰
2. å¯¹è±¡ä¹‹é—´çš„ç©ºé—´å…³ç³?
3. åœºæ™¯çš„æ•´ä½“æ°›å›´å’ŒèƒŒæ™¯
4. ä»»ä½•æ–‡å­—æˆ–ç¬¦å?
5. å›¾ç‰‡çš„è‰ºæœ¯é£æ ¼æˆ–æ‹æ‘„æŠ€æœ?
6. å¯èƒ½çš„ä¸–ç•ŒçŸ¥è¯†å…³è?

è¯·ç”¨è¯¦å°½çš„æ®µè½å½¢å¼æè¿°ï¼Œè€Œéç®€å•çš„åˆ—è¡¨ã€?
```

### æ•°æ®è´¨é‡å¯¹æ¯”

| æŒ‡æ ‡ | LAION Caption | ShareGPT4V Caption |
| :--- | :--- | :--- |
| **å¹³å‡é•¿åº¦** | ~12 è¯?| ~150 è¯?|
| **ç»†èŠ‚è¦†ç›–** | ä»…ä¸»ä½?| å…¨é¢ç»†èŠ‚ |
| **ç©ºé—´å…³ç³»** | æ—?| æœ?|
| **ä¸–ç•ŒçŸ¥è¯†** | æ—?| æœ?|

### è®­ç»ƒæ•ˆæœ

å®éªŒè¯æ˜ï¼Œä½¿ç”¨é«˜å¯†åº¦ Caption é¢„è®­ç»ƒï¼š

- è§†è§‰ç‰¹å¾ä¸è¯­è¨€æ¦‚å¿µå¯¹é½æ›´ç²¾ç¡?
- ç»†ç²’åº¦ä»»åŠ¡ï¼ˆOCRã€å®šä½ï¼‰æ˜¾è‘—æå‡
- å¹»è§‰é—®é¢˜å‡å°‘

---

## BLIP CapFiltï¼šæ•°æ®è‡ªä¸¾çš„è‰ºæœ¯

### æ ¸å¿ƒæœºåˆ¶

**CapFilt = Captioner + Filter**

```mermaid
flowchart LR
    WEB[ç½‘ç»œå›¾æ–‡å¯¹] --> CAP[
        Captioner - 
        ç”ŸæˆåˆæˆCaption
    ]
    WEB --> ORI[åŸå§‹Caption]
    CAP --> FILTER[
        Filter - 
        è¯„åˆ†è¿‡æ»¤
    ]
    ORI --> FILTER
    FILTER -- é«˜åˆ†ä¿ç•™ --> CLEAN[æ¸…æ´—åæ•°æ®]
    FILTER -- ä½åˆ†ä¸¢å¼ƒ --> DROP[âŒ]
```

### Captioner è®­ç»ƒ

**ç¬¬ä¸€æ­?*ï¼šåœ¨é«˜è´¨é‡äººå·¥æ ‡æ³¨æ•°æ®ï¼ˆå¦‚COCOï¼‰ä¸Šè®­ç»ƒå›¾åƒæè¿°æ¨¡å‹

**ç¬¬äºŒæ­?*ï¼šå¯¹ç½‘ç»œå›¾åƒç”Ÿæˆ**åˆæˆCaption** (synthetic captions)

**ä¼˜åŠ¿**ï¼?

- åˆæˆCaptioné€šå¸¸æ¯”å™ªå£°çš„Alt-textæ›´å‡†ç¡?
- èƒ½å¤Ÿç”Ÿæˆè¯¦ç»†ã€ç»“æ„åŒ–çš„æè¿?
- è¦†ç›–Alt-texté—æ¼çš„è§†è§‰ç»†èŠ?

### Filter è¯„åˆ†æœºåˆ¶

**ITMï¼ˆImage-Text Matchingï¼‰åˆ†ç±»å™¨**ï¼?

```python
def filter_score(image, text_original, text_synthetic):
    """ä½¿ç”¨ITMæ¨¡å‹è¯„ä¼°å›¾æ–‡åŒ¹é…åº?""
    
    # ITMåˆ†æ•°ï¼šå›¾æ–‡åŒ¹é…äºŒåˆ†ç±»å™¨ï¼ˆ0-1ä¹‹é—´ï¼?
    score_original = itm_model(image, text_original)
    score_synthetic = itm_model(image, text_synthetic)
    
    # ç­–ç•¥ï¼šå–æœ€é«˜åˆ†çš„Caption
    if score_synthetic > score_original:
        return text_synthetic, score_synthetic
    elif score_original > threshold:  # thresholdé€šå¸¸ä¸?.8
        return text_original, score_original
    else:
        return None, 0  # ä¸¤è€…éƒ½ä¸åˆæ ¼ï¼Œä¸¢å¼ƒè¯¥æ ·æœ?
```

**è¿‡æ»¤ç­–ç•¥**ï¼?

1. **ä¼˜å…ˆåˆæˆ**ï¼šå¦‚æœåˆæˆCaptionå¾—åˆ†æ›´é«˜ï¼Œä½¿ç”¨åˆæˆ?
2. **ä¿ç•™åŸå§‹**ï¼šå¦‚æœåŸå§‹Captionè¶³å¤Ÿå¥½ï¼ˆ>é˜ˆå€¼ï¼‰ï¼Œä¿ç•?
3. **åŒé‡æ·˜æ±°**ï¼šå¦‚æœä¸¤è€…éƒ½ä¸è¡Œï¼Œä¸¢å¼ƒæ ·æœ?

### è‡ªä¸¾å¾ªç¯

```mermaid
flowchart TB
    INIT[åˆå§‹é«˜è´¨é‡æ•°æ®] --> TRAIN1[è®­ç»ƒCaptioner v1]
    TRAIN1 --> GEN1[ç”ŸæˆåˆæˆCaption]
    GEN1 --> FILTER1[Filteræ¸…æ´—]
    FILTER1 --> DATA1[æ¸…æ´—æ•°æ®é›?v1]
    DATA1 --> TRAIN2[è®­ç»ƒCaptioner v2]
    TRAIN2 --> GEN2[ç”Ÿæˆæ›´å¥½Caption]
    GEN2 --> FINAL[æœ€ç»ˆæ•°æ®é›†]
```

**è¿­ä»£æ”¹è¿›**ï¼?

- ç¬?è½®ï¼šç”¨äººå·¥æ•°æ®è®­ç»?â†?ç”ŸæˆåˆæˆCaption
- ç¬?è½®ï¼šç”¨æ¸…æ´—æ•°æ®é‡æ–°è®­ç»?â†?ç”Ÿæˆæ›´é«˜è´¨é‡Captionï¼ˆå¯é€‰ï¼‰

### æ•ˆæœéªŒè¯

| è®­ç»ƒæ•°æ® | è§„æ¨¡ | VQAå‡†ç¡®ç?| COCO CIDEr | è¯´æ˜ |
| :--- | :--- | :--- | :--- | :--- |
| åŸå§‹LAION | 1.8äº¿å¯¹ | 78.3 | 121.6 | æœªæ¸…æ´?|
| CapFiltæ¸…æ´—å?| **1.29äº¿å¯¹** | **82.4** | **130.5** | è´¨é‡>æ•°é‡ |
| ä»…åˆæˆCaption | 1.29äº¿å¯¹ | 80.1 | 125.3 | ç•¥ä½äºæ··å?|

**å…³é”®å‘ç°**ï¼?

- âœ?**è´¨é‡èƒœäºæ•°é‡**ï¼?.29äº¿æ¸…æ´—æ•°æ®è¶…è¿?.8äº¿åŸå§‹æ•°æ?
- âœ?**åˆæˆ+åŸå§‹æ··åˆ**ï¼šæ•ˆæœæœ€ä½?
- âœ?**å¹»è§‰å‡å°‘**ï¼šFilteræ·˜æ±°äº†ä¸åŒ¹é…çš„æè¿?

### Caption è´¨é‡å¯¹æ¯”

| æ¥æº | ç¤ºä¾‹ | ç‰¹ç‚¹ |
| :--- | :--- | :--- |
| **ç½‘ç»œAlt-text** | "beach photo" | è¿‡äºç®€çŸ?|
| **CapFiltåˆæˆ** | "The image captures an exhilarating moment of a surfer riding a powerful wave. The surfer, clad in a black wetsuit, demonstrates remarkable balance and skill as they navigate the turbulent waters..." | è¯¦ç»†ã€ä¸°å¯?|

---

## åŠ¨æ€åˆ†è¾¨ç‡ï¼šAnyRes

### é—®é¢˜ï¼šå›ºå®šåˆ†è¾¨ç‡çš„å±€é™?

ä¼ ç»Ÿæ–¹æ³•å°†æ‰€æœ‰å›¾åƒç¼©æ”¾åˆ°å›ºå®šåˆ†è¾¨ç‡ï¼ˆå¦?336Ã—336ï¼‰ï¼š

| åŸå§‹å›¾åƒ | ç¼©æ”¾å?| é—®é¢˜ |
| :--- | :--- | :--- |
| é«˜æ¸…ç…§ç‰‡ 4K | 336Ã—336 | ç»†èŠ‚ä¸¢å¤± |
| æ–‡æ¡£æˆªå›¾ | 336Ã—336 | æ–‡å­—æ¨¡ç³Š |
| é•¿å›¾/å®½å›¾ | 336Ã—336 | ä¸¥é‡å˜å½¢ |

### LLaVA-NeXT AnyRes æ–¹æ¡ˆ

```mermaid
flowchart TB
    IMG[è¾“å…¥å›¾åƒ - ä»»æ„åˆ†è¾¨ç‡] --> RATIO[è®¡ç®—å®½é«˜æ¯”]
    RATIO --> SELECT[é€‰æ‹©æœ€ä½³ç½‘æ ?br/>ä»é¢„å®šä¹‰é…ç½®ä¸­]
    SELECT --> SPLIT[åˆ‡åˆ†ä¸ºå­å›¾]
    IMG --> RESIZE[ç¼©æ”¾ä¸ºå…¨å±€è§†å›¾]
    SPLIT --> VIT1[ViT ç¼–ç ]
    RESIZE --> VIT2[ViT ç¼–ç ]
    VIT1 --> CAT[ç‰¹å¾æ‹¼æ¥]
    VIT2 --> CAT
    CAT --> PROJ[Projector]
    PROJ --> LLM
```

### ç½‘æ ¼é…ç½®

```python
GRID_CONFIGS = [
    (1, 1),  # æ­£æ–¹å½¢å°å›?
    (1, 2),  # å®½å›¾
    (2, 1),  # é«˜å›¾
    (2, 2),  # å¤§æ­£æ–¹å½¢
    (1, 3),  # è¶…å®½å›?
    (3, 1),  # è¶…é«˜å›?
    (2, 3),  # å®½å¤§å›?
    (3, 2),  # é«˜å¤§å›?
]

def select_grid(image_width, image_height, patch_size=336):
    aspect_ratio = image_width / image_height
    # é€‰æ‹©æœ€åŒ¹é…å®½é«˜æ¯”çš„ç½‘æ ¼é…ç½®
    best_grid = min(GRID_CONFIGS, 
                    key=lambda g: abs(g[0]/g[1] - aspect_ratio))
    return best_grid
```

### Token æ•°é‡è®¡ç®—

| é…ç½® | å­å›¾æ•?| å­å›¾ Token | å…¨å±€ Token | æ€»è®¡ |
| :--- | :--- | :--- | :--- | :--- |
| **1Ã—1** | 1 | 576 | 576 | 1152 |
| **2Ã—2** | 4 | 2304 | 576 | 2880 |
| **3Ã—2** | 6 | 3456 | 576 | 4032 |

### æ„å¤–æ”¶è·ï¼šé›¶æ ·æœ¬è§†é¢‘ç†è§£

AnyRes çš„è®¾è®¡æ„å¤–å¸¦æ¥è§†é¢‘ç†è§£èƒ½åŠ›ï¼š

- è§†é¢‘å¸?= åŠ¨æ€åˆ†è¾¨ç‡çš„å›¾åƒåºåˆ?
- å°†å¤šå¸§ä½œä¸?å­å›¾"è¾“å…¥
- æ— éœ€ä¸“é—¨è§†é¢‘è®­ç»ƒ

---

## æ•°æ®æ ¼å¼æ ‡å‡†

### é¢„è®­ç»ƒæ ¼å¼?

```json
{
  "image": "path/to/image.jpg",
  "caption": "A detailed description of the image..."
}
```

### æŒ‡ä»¤å¾®è°ƒæ ¼å¼

```json
{
  "image": "path/to/image.jpg",
  "conversations": [
    {"from": "human", "value": "<image>\nDescribe this image."},
    {"from": "gpt", "value": "This image shows..."}
  ]
}
```

### å¤šå›¾å¯¹è¯æ ¼å¼

```json
{
  "images": ["img1.jpg", "img2.jpg"],
  "conversations": [
    {"from": "human", "value": "<image>\n<image>\nCompare these two images."},
    {"from": "gpt", "value": "The first image shows... while the second..."}
  ]
}
```

---

## æ•°æ®è´¨é‡è¯„ä¼°

### è‡ªåŠ¨åŒ–æŒ‡æ ?

| æŒ‡æ ‡ | è®¡ç®—æ–¹å¼ | ç”¨é€?|
| :--- | :--- | :--- |
| **CLIP Score** | å›¾æ–‡ä½™å¼¦ç›¸ä¼¼åº?| è¯­ä¹‰ç›¸å…³æ€?|
| **Aesthetic Score** | LAION ç¾å­¦æ¨¡å‹ | å›¾åƒè´¨é‡ |
| **Text Complexity** | è¯æ±‡å¤šæ ·æ€?é•¿åº¦ | Caption ä¸°å¯Œåº?|
| **Perplexity** | è¯­è¨€æ¨¡å‹å›°æƒ‘åº?| Caption æµç•…åº?|

### äººå·¥è¯„ä¼°ç»´åº¦

| ç»´åº¦ | è¯„ä¼°å†…å®¹ |
| :--- | :--- |
| **å‡†ç¡®æ€?* | Caption æ˜¯å¦çœŸå®æè¿°å›¾åƒ |
| **å®Œæ•´æ€?* | æ˜¯å¦è¦†ç›–ä¸»è¦è§†è§‰å…ƒç´  |
| **ç»†èŠ‚åº?* | ç©ºé—´å…³ç³»ã€å±æ€§æ˜¯å¦å……åˆ?|
| **ç›¸å…³æ€?* | æ˜¯å¦æœ‰æ— å…³ä¿¡æ?|

---

## å®è·µå»ºè®®

### æ•°æ®æ”¶é›†ç­–ç•¥

| é˜¶æ®µ | æ•°æ®ç±»å‹ | è§„æ¨¡ | è´¨é‡è¦æ±‚ |
| :--- | :--- | :--- | :--- |
| **é¢„è®­ç»?* | ç½‘ç»œçˆ¬å– | 10M+ | ä¸­ç­‰ |
| **å¤šä»»åŠ?* | å…¬å¼€æ•°æ®é›?| 1M+ | è¾ƒé«˜ |
| **æŒ‡ä»¤å¾®è°ƒ** | äººå·¥/åˆæˆ | 100K+ | æé«˜ |

### å¸¸è§é™·é˜±

::: danger æ•°æ®æ³„æ¼
ç¡®ä¿è®­ç»ƒæ•°æ®ä¸è¯„æµ‹æ•°æ®æ— é‡å ï¼ä½¿ç”¨å»é‡å’Œäº¤å‰æ£€æŸ¥ã€?
:::

::: warning åˆ†å¸ƒåå·®
ç½‘ç»œæ•°æ®å­˜åœ¨ä¸¥é‡çš„é•¿å°¾åˆ†å¸ƒï¼Œç½•è§æ¦‚å¿µè¦†ç›–ä¸è¶³ã€‚è€ƒè™‘æ•°æ®å¢å¼ºæˆ–åˆæˆè¡¥å……ã€?
:::

---

## å‚è€ƒèµ„æº?

| èµ„æº | è¯´æ˜ |
| :--- | :--- |
| [LAION-5B](https://laion.ai/blog/laion-5b/) | æ•°æ®é›†ä¸»é¡?|
| [ShareGPT4V](https://sharegpt4v.github.io/) | é«˜è´¨é‡?Caption |
| [LLaVA-NeXT](https://llava-vl.github.io/blog/2024-01-30-llava-next/) | AnyRes æŠ€æœ?|
| [img2dataset](https://github.com/rom1504/img2dataset) | æ•°æ®ä¸‹è½½å·¥å…· |

